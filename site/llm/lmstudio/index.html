
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Modern threat intelligence collection and analysis platform">
      
      
      
      
        <link rel="prev" href="../model-selection/">
      
      
        <link rel="next" href="../extract-agent-eval/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>LM Studio Integration - Huntable CTI Studio</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#lm-studio-integration" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Huntable CTI Studio" class="md-header__button md-logo" aria-label="Huntable CTI Studio" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Huntable CTI Studio
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              LM Studio Integration
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../quickstart/" class="md-tabs__link">
        
  
  
    
  
  Quickstart

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../getting-started/installation/" class="md-tabs__link">
          
  
  
  Getting Started

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../concepts/huntables/" class="md-tabs__link">
          
  
  
  Concepts

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../guides/add-feed/" class="md-tabs__link">
          
  
  
  Guides

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../architecture/overview/" class="md-tabs__link">
          
  
  
  Architecture

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../features/sigma-rules/" class="md-tabs__link">
          
  
  
  Features

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../model-selection/" class="md-tabs__link">
          
  
  
  LLM & Models

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../ml-training/hunt-scoring/" class="md-tabs__link">
          
  
  
  ML Training

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../reference/cli/" class="md-tabs__link">
          
  
  
  Reference

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../development/setup/" class="md-tabs__link">
          
  
  
  Development

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../prompts/eval-bundle/" class="md-tabs__link">
          
  
  
  Prompts

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../contributing/" class="md-tabs__link">
        
  
  
    
  
  Contributing

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../changelog/" class="md-tabs__link">
        
  
  
    
  
  Changelog

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Huntable CTI Studio" class="md-nav__button md-logo" aria-label="Huntable CTI Studio" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Huntable CTI Studio
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quickstart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quickstart
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Getting Started
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Getting Started
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Installation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/configuration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Configuration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/first-workflow/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    First Workflow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Concepts
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Concepts
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../concepts/huntables/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Huntables
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../concepts/agents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Agents
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../concepts/pipelines/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Pipelines
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../concepts/observables/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Observables
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Guides
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Guides
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/add-feed/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Add a Feed
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/extract-observables/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Extract Observables
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/generate-sigma/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Generate Sigma Rules
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/evaluate-models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Evaluate Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/backup-and-restore/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Backup & Restore
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/source-config/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Source Configuration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/memory-tuning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Memory Tuning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Architecture
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Architecture
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../architecture/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../architecture/workflow-data-flow/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Workflow Data Flow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../architecture/scoring/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Scoring
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../architecture/chunking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chunking
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../architecture/qa-loops/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    QA Loops
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Features
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Features
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../features/sigma-rules/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Sigma Detection Rules
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../features/content-filtering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Content Filtering
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../features/os-detection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    OS Detection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../features/cmdline-preprocessor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Cmdline Preprocessor
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../features/rag-search/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    RAG Search
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../features/observable-evaluation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Observable Evaluation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" checked>
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    LLM & Models
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    LLM & Models
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model-selection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Model Selection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    LM Studio Integration
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    LM Studio Integration
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Overview
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    <span class="md-ellipsis">
      
        Setup
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#api-usage" class="md-nav__link">
    <span class="md-ellipsis">
      
        API Usage
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#troubleshooting" class="md-nav__link">
    <span class="md-ellipsis">
      
        Troubleshooting
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#environment-variables" class="md-nav__link">
    <span class="md-ellipsis">
      
        Environment Variables
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Environment Variables">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#required" class="md-nav__link">
    <span class="md-ellipsis">
      
        Required
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#per-agent-model-overrides" class="md-nav__link">
    <span class="md-ellipsis">
      
        Per-Agent Model Overrides
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recommended-settings-for-deterministic-scoring" class="md-nav__link">
    <span class="md-ellipsis">
      
        Recommended Settings (for Deterministic Scoring)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-configuration-must-be-set-in-lmstudio-ui" class="md-nav__link">
    <span class="md-ellipsis">
      
        Model Configuration (Must be set in LMStudio UI)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model Configuration (Must be set in LMStudio UI)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quantization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quantization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#context-length" class="md-nav__link">
    <span class="md-ellipsis">
      
        Context Length
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Context Length">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#context-length-requirements-by-use-case" class="md-nav__link">
    <span class="md-ellipsis">
      
        Context Length Requirements by Use Case
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm-studio-040-optional-improvements" class="md-nav__link">
    <span class="md-ellipsis">
      
        LM Studio 0.4.0+ (optional improvements)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#test-endpoint" class="md-nav__link">
    <span class="md-ellipsis">
      
        Test Endpoint
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#performance-benchmarks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Performance Benchmarks
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#local-llm-performance-testing" class="md-nav__link">
    <span class="md-ellipsis">
      
        Local LLM Performance Testing
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Local LLM Performance Testing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#active-providers" class="md-nav__link">
    <span class="md-ellipsis">
      
        Active Providers
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#expected-performance-improvements" class="md-nav__link">
    <span class="md-ellipsis">
      
        Expected Performance Improvements
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#setup-instructions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Setup Instructions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Setup Instructions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-mlx-apple-metal-fastest" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. MLX (Apple Metal) - FASTEST
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-llamacpp-metal-backend-very-fast" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. llama.cpp (Metal Backend) - VERY FAST
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-lm-studio-openai-compatible-easy-setup" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. LM Studio (OpenAI-Compatible) - EASY SETUP
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#performance-testing" class="md-nav__link">
    <span class="md-ellipsis">
      
        Performance Testing
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Performance Testing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#automated-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      
        Automated Benchmark
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manual-testing" class="md-nav__link">
    <span class="md-ellipsis">
      
        Manual Testing
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#benchmark-results" class="md-nav__link">
    <span class="md-ellipsis">
      
        Benchmark Results
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuration-guide" class="md-nav__link">
    <span class="md-ellipsis">
      
        Configuration Guide
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Configuration Guide">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#environment-variables_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Environment Variables
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#provider-selection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Provider Selection
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#troubleshooting_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Troubleshooting
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Troubleshooting">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#common-issues" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Issues
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Performance Optimization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-requirements" class="md-nav__link">
    <span class="md-ellipsis">
      
        Memory Requirements
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-recommendations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Model Recommendations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model Recommendations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#for-maximum-speed-apple-silicon" class="md-nav__link">
    <span class="md-ellipsis">
      
        For Maximum Speed (Apple Silicon)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-best-qualityspeed-balance" class="md-nav__link">
    <span class="md-ellipsis">
      
        For Best Quality/Speed Balance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-maximum-quality" class="md-nav__link">
    <span class="md-ellipsis">
      
        For Maximum Quality
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#integration-with-cti-scraper" class="md-nav__link">
    <span class="md-ellipsis">
      
        Integration with CTI Scraper
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Integration with CTI Scraper">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rag-system-integration" class="md-nav__link">
    <span class="md-ellipsis">
      
        RAG System Integration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#api-integration" class="md-nav__link">
    <span class="md-ellipsis">
      
        API Integration
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      
        Best Practices
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#support" class="md-nav__link">
    <span class="md-ellipsis">
      
        Support
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../extract-agent-eval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Extract Agent Evaluation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ML Training
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    ML Training
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ml-training/hunt-scoring/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Hunt Scoring
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ml-training/database-training/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Database Training
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_10" >
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            
  
    Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/cli/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    CLI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/schemas/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Schemas
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/ml-features/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ML Feature Definitions
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/versioning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Versioning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_11" >
        
          
          <label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Development
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            
  
    Development
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../development/setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Setup
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../development/testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Testing Strategy
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../development/manual-testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Manual Testing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../development/web-app-testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Web App Testing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../development/debugging/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Debugging
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../development/database-queries/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Database Queries
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../development/allure-reports/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Allure Reports
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../development/multi-instance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Multi-Instance
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../development/workflow-queue/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Workflow Queue
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../development/search-queries/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Search Queries
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_12" >
        
          
          <label class="md-nav__link" for="__nav_12" id="__nav_12_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Prompts
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_12">
            <span class="md-nav__icon md-icon"></span>
            
  
    Prompts
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../prompts/eval-bundle/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Eval Bundle Analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../prompts/huntquery-eval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Hunt Query Eval
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../prompts/proctree-eval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Process Tree Eval
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contributing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Contributing
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../changelog/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Changelog
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="lm-studio-integration">LM Studio Integration<a class="headerlink" href="#lm-studio-integration" title="Permanent link">&para;</a></h1>
<h2 id="overview">Overview<a class="headerlink" href="#overview" title="Permanent link">&para;</a></h2>
<p>This guide covers setting up and optimizing LM Studio for local LLM inference with Huntable CTI Studio.</p>
<h2 id="setup">Setup<a class="headerlink" href="#setup" title="Permanent link">&para;</a></h2>
<ol>
<li><strong>Start LMStudio</strong>:</li>
<li>Open LMStudio</li>
<li>Go to Developer tab â†’ Local Server</li>
<li>Enable "Serve on local network"</li>
<li>Start server (default port: 1234)</li>
<li>
<p>Load your preferred model</p>
</li>
<li>
<p><strong>Run CTIScraper with LMStudio</strong>:
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="c1"># Start services (LMStudio config is already in docker-compose.yml)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>docker-compose<span class="w"> </span>up<span class="w"> </span>web
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="c1"># Or start all services</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>docker-compose<span class="w"> </span>up
</code></pre></div></p>
</li>
<li>
<p><strong>Configure Model Name</strong>:</p>
</li>
<li>Edit <code>.env</code> file or set environment variables</li>
<li>Set <code>LMSTUDIO_MODEL</code> to your loaded model name</li>
<li>Example: <code>LMSTUDIO_MODEL=deepseek/deepseek-r1-0528-qwen3-8b</code></li>
<li>The main <code>docker-compose.yml</code> already includes LMStudio configuration pointing to <code>host.docker.internal:1234/v1</code></li>
</ol>
<h2 id="api-usage">API Usage<a class="headerlink" href="#api-usage" title="Permanent link">&para;</a></h2>
<p>In the web interface, select <code>lmstudio</code> as the LLM provider in chat settings.</p>
<h2 id="troubleshooting">Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Connection refused</strong>: Ensure LMStudio server is running and accessible</li>
<li><strong>Model not found</strong>: Verify model name matches exactly in LMStudio</li>
<li><strong>Timeout errors</strong>: Increase timeout in <code>_call_lmstudio()</code> method if needed</li>
<li><strong>Context length errors</strong>: </li>
<li>Error: "context overflow" or "context length of only X tokens, which is not enough"</li>
<li><strong>Solution</strong>: Increase context length in LMStudio UI (Context tab) to at least 16384 tokens for article scoring</li>
<li><strong>For article scoring</strong>: Use 16384-32768 tokens minimum</li>
<li>Model must be reloaded after changing context length</li>
</ul>
<h2 id="environment-variables">Environment Variables<a class="headerlink" href="#environment-variables" title="Permanent link">&para;</a></h2>
<h3 id="required">Required<a class="headerlink" href="#required" title="Permanent link">&para;</a></h3>
<ul>
<li><code>LMSTUDIO_API_URL</code>: LMStudio API endpoint (default: <code>http://host.docker.internal:1234/v1</code>)</li>
<li><code>LMSTUDIO_MODEL</code>: Model name in LMStudio (default: <code>deepseek/deepseek-r1-0528-qwen3-8b</code>)</li>
</ul>
<h3 id="per-agent-model-overrides">Per-Agent Model Overrides<a class="headerlink" href="#per-agent-model-overrides" title="Permanent link">&para;</a></h3>
<ul>
<li><code>LMSTUDIO_MODEL_RANK</code>: Model for ranking agent (default: <code>qwen/qwen3-4b-2507</code>)</li>
<li><code>LMSTUDIO_MODEL_EXTRACT</code>: Model for extraction agent (default: <code>qwen/qwen3-4b-2507</code>)</li>
<li><code>LMSTUDIO_MODEL_SIGMA</code>: Model for SIGMA generation (default: <code>qwen/qwen3-4b-2507</code>)</li>
<li><code>LMSTUDIO_MAX_CONTEXT</code>: Maximum context window size (tokens). Must also be set in LM Studio UI.</li>
</ul>
<h3 id="recommended-settings-for-deterministic-scoring">Recommended Settings (for Deterministic Scoring)<a class="headerlink" href="#recommended-settings-for-deterministic-scoring" title="Permanent link">&para;</a></h3>
<ul>
<li><code>LMSTUDIO_TEMPERATURE</code>: Temperature for inference (default: <code>0.0</code> for deterministic scoring)</li>
<li><code>LMSTUDIO_TOP_P</code>: Top-p sampling parameter (default: <code>0.9</code>)</li>
<li><code>LMSTUDIO_SEED</code>: Random seed for deterministic outputs (default: <code>42</code>)</li>
</ul>
<h2 id="model-configuration-must-be-set-in-lmstudio-ui">Model Configuration (Must be set in LMStudio UI)<a class="headerlink" href="#model-configuration-must-be-set-in-lmstudio-ui" title="Permanent link">&para;</a></h2>
<h3 id="quantization">Quantization<a class="headerlink" href="#quantization" title="Permanent link">&para;</a></h3>
<p>Quantization (Q4_K_M, Q6_K, Q8_0) must be set in LMStudio UI when loading the model - this cannot be controlled via API. For speed: Q4_K_M. For accuracy: Q6_K or Q8_0.</p>
<h3 id="context-length">Context Length<a class="headerlink" href="#context-length" title="Permanent link">&para;</a></h3>
<p><strong>Context length cannot be set remotely via the OpenAI-compatible HTTP API.</strong> The context window must be configured when loading the model in LMStudio UI or CLI:</p>
<p><strong>Automated (Recommended):</strong>
- Use the provided script to load with correct context length:
  <div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>./scripts/load_lmstudio_model.sh
</code></pre></div>
  - Reads <code>LMSTUDIO_MODEL</code> and <code>LMSTUDIO_MAX_CONTEXT</code> from <code>.env</code>
  - Automatically loads model with specified context length
  - Run this after starting LMStudio server, or add to startup sequence</p>
<p><strong>Manual Options:</strong>
- <strong>In LMStudio UI</strong>: 
  1. Load your model in LMStudio
  2. Go to the <strong>Context</strong> tab in the right panel
  3. Adjust the <strong>Context Length</strong> slider (or enter value directly)
  4. Model must be reloaded for changes to take effect
- <strong>Via CLI</strong>: Use <code>lms load &lt;model-name&gt; --context-length &lt;tokens&gt;</code></p>
<p><strong>Important:</strong> 
- Context length is set at model load time and cannot be changed via API calls
- Exceeding the model's maximum context length will cause errors like: "context overflow" or "context length of only X tokens, which is not enough"
- Default context windows: 1B models (~2048), 3B models (~4096), 8B models (~8192), 20B+ models (~4096-8192 default)</p>
<p><strong>Docker Compose variance:</strong> In <code>docker-compose.yml</code>, the web service and worker/workflow_worker services can set different per-model context lengths (e.g. <code>LMSTUDIO_CONTEXT_LENGTH_&lt;model_slug&gt;</code>). For example, the web service may use 16384 for article scoring while workers use 4096. Check the compose file for your service if you see context-length errors in one component but not another.</p>
<h4 id="context-length-requirements-by-use-case">Context Length Requirements by Use Case<a class="headerlink" href="#context-length-requirements-by-use-case" title="Permanent link">&para;</a></h4>
<p><strong>Article Scoring (SIGMA Huntability Ranking):</strong>
- <strong>Minimum Required:</strong> 8192 tokens (for smaller articles)
- <strong>Recommended:</strong> 16384-32768 tokens (for full article analysis)
- <strong>Prompt Size:</strong> ~6000-8000 input tokens (full rubric + article content)
- <strong>Error if too small:</strong> "Trying to keep the first X tokens when context overflows. However, the model is loaded with context length of only Y tokens"</p>
<p><strong>SIGMA Rule Generation:</strong>
- CTIScraper automatically truncates content based on detected model size:
  - 1B models: ~550 tokens of content (~2200 chars)
  - 3B models: ~2600 tokens of content (~10400 chars)<br />
  - 8B+ models: ~6700 tokens of content (~26800 chars)</p>
<p><strong>Chat/RAG Queries:</strong>
- Varies by conversation length
- Typically requires 4096-8192 tokens for standard queries</p>
<p>The application uses the OpenAI-compatible HTTP API (<code>/v1/chat/completions</code>), which does not support runtime context length configuration. If you need programmatic context length control, you would need to switch to the LMStudio Python SDK, which is not currently implemented.</p>
<h2 id="lm-studio-040-optional-improvements">LM Studio 0.4.0+ (optional improvements)<a class="headerlink" href="#lm-studio-040-optional-improvements" title="Permanent link">&para;</a></h2>
<p>The following features from <a href="https://lmstudio.ai/blog/0.4.0">LM Studio 0.4.0</a> are relevant to CTIScraper:</p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Relevance</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>llmster (headless daemon)</strong></td>
<td>High</td>
<td>Run LM Studio backend without the GUI on a server/GPU rig. Install: <code>curl -fsSL https://lmstudio.ai/install.sh \| bash</code> then <code>lms daemon up</code>, <code>lms server start</code>. Point <code>LMSTUDIO_API_URL</code> at that host. No app code change.</td>
</tr>
<tr>
<td><strong>Parallel requests (continuous batching)</strong></td>
<td>High</td>
<td>Multiple concurrent requests to the same model instead of queuing. In LM Studio model loader: set <strong>Max Concurrent Predictions</strong> (e.g. 4) and keep <strong>Unified KV Cache</strong> enabled. Improves throughput for workflow (rank, extract, sigma) and multi-article runs. No app code change.</td>
</tr>
<tr>
<td><strong>Stateful <code>/v1/chat</code> API</strong></td>
<td>Medium</td>
<td>New endpoint with <code>response_id</code> / <code>previous_response_id</code> for smaller follow-up payloads and response stats. Current app uses stateless <code>/chat/completions</code>; migrating is optional and would require a dedicated client path and tests.</td>
</tr>
<tr>
<td><strong>Permission keys</strong></td>
<td>Low</td>
<td>If exposing LM Studio (or llmster) on a shared network, generate keys in Settings â†’ Server and pass via header. Document when we add optional auth to LM Studio requests.</td>
</tr>
</tbody>
</table>
<p><strong>Recommendation:</strong> Document llmster and parallel-request settings for users who run LM Studio 0.4.0+; consider <code>/v1/chat</code> only if we need smaller payloads or response metrics for multi-turn flows.</p>
<h2 id="test-endpoint">Test Endpoint<a class="headerlink" href="#test-endpoint" title="Permanent link">&para;</a></h2>
<p>Use <code>POST /api/test-lmstudio</code> from the web UI to validate LMStudio connectivity. This endpoint checks that the LMStudio server is reachable and the configured model is loaded and responding.</p>
<hr />
<h2 id="performance-benchmarks">Performance Benchmarks<a class="headerlink" href="#performance-benchmarks" title="Permanent link">&para;</a></h2>
<h2 id="local-llm-performance-testing">Local LLM Performance Testing<a class="headerlink" href="#local-llm-performance-testing" title="Permanent link">&para;</a></h2>
<h3 id="active-providers">Active Providers<a class="headerlink" href="#active-providers" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>LM Studio</strong> (OpenAI-compatible) â€” Active local model provider with GUI server mode</li>
<li><strong>OpenAI</strong> (Cloud) â€” GPT-4o-mini API</li>
<li><strong>Anthropic</strong> (Cloud) â€” Claude Haiku API</li>
</ol>
<blockquote>
<p><strong>Note</strong>: MLX and llama.cpp providers are planned but not yet implemented.</p>
</blockquote>
<h2 id="expected-performance-improvements">Expected Performance Improvements<a class="headerlink" href="#expected-performance-improvements" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Provider</th>
<th>1B Model</th>
<th>7B Model</th>
<th>Setup Complexity</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MLX</strong></td>
<td>2-3s</td>
<td>5-8s</td>
<td>Medium</td>
<td>Maximum speed on Apple Silicon</td>
</tr>
<tr>
<td><strong>llama.cpp</strong></td>
<td>2-4s</td>
<td>6-10s</td>
<td>Medium</td>
<td>Balanced speed and compatibility</td>
</tr>
<tr>
<td><strong>LM Studio</strong></td>
<td>3-5s</td>
<td>8-12s</td>
<td>Low</td>
<td>Easy setup with GUI</td>
</tr>
</tbody>
</table>
<h2 id="setup-instructions">Setup Instructions<a class="headerlink" href="#setup-instructions" title="Permanent link">&para;</a></h2>
<h3 id="1-mlx-apple-metal-fastest">1. MLX (Apple Metal) - FASTEST<a class="headerlink" href="#1-mlx-apple-metal-fastest" title="Permanent link">&para;</a></h3>
<p><strong>Requirements:</strong>
- macOS with Apple Silicon (M1/M2/M3)
- Python 3.11+ (Docker uses 3.11; local MLX setup supports 3.8+)</p>
<p><strong>Installation:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="c1"># Install MLX packages</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>pip<span class="w"> </span>install<span class="w"> </span>mlx-lm
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="c1"># Download models using setup script</span>
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>./scripts/setup_local_models.sh<span class="w"> </span>--with-mlx<span class="w"> </span>--all-models
</code></pre></div></p>
<p><strong>Configuration:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="c1"># In your .env file</span>
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="nv">MLX_ENABLED</span><span class="o">=</span><span class="nb">true</span>
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="nv">MLX_MODEL_PATH</span><span class="o">=</span>models/mlx/llama-3.2-1b-instruct
</code></pre></div></p>
<p><strong>Manual Model Download:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="c1"># Download specific model</span>
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;</span>
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="s2">from huggingface_hub import snapshot_download</span>
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="s2">snapshot_download(</span>
<a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a><span class="s2">    repo_id=&#39;mlx-community/Llama-3.2-1B-Instruct-4bit&#39;,</span>
<a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="s2">    local_dir=&#39;models/mlx/llama-3.2-1b-instruct&#39;,</span>
<a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a><span class="s2">    local_dir_use_symlinks=False</span>
<a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a><span class="s2">)</span>
</code></pre></div></p>
<h3 id="2-llamacpp-metal-backend-very-fast">2. llama.cpp (Metal Backend) - VERY FAST<a class="headerlink" href="#2-llamacpp-metal-backend-very-fast" title="Permanent link">&para;</a></h3>
<p><strong>Requirements:</strong>
- macOS with Apple Silicon
- Python 3.11+ (Docker uses 3.11; local llama.cpp setup supports 3.8+)</p>
<p><strong>Installation:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="c1"># Install llama-cpp-python with Metal support</span>
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>pip<span class="w"> </span>install<span class="w"> </span>llama-cpp-python
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>
<a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="c1"># Download GGUF models</span>
<a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>./scripts/setup_local_models.sh<span class="w"> </span>--with-llamacpp<span class="w"> </span>--all-models
</code></pre></div></p>
<p><strong>Configuration:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="c1"># In your .env file</span>
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="nv">LLAMACPP_ENABLED</span><span class="o">=</span><span class="nb">true</span>
<a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="nv">LLAMACPP_MODEL_PATH</span><span class="o">=</span>models/gguf/llama-3.2-1b-instruct.gguf
</code></pre></div></p>
<p><strong>Manual Model Download:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="c1"># Download GGUF file</span>
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;</span>
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a><span class="s2">from huggingface_hub import hf_hub_download</span>
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="s2">hf_hub_download(</span>
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="s2">    repo_id=&#39;microsoft/Llama-3.2-1B-Instruct-GGUF&#39;,</span>
<a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a><span class="s2">    filename=&#39;*.gguf&#39;,</span>
<a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a><span class="s2">    local_dir=&#39;models/gguf&#39;,</span>
<a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a><span class="s2">    local_dir_use_symlinks=False</span>
<a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a><span class="s2">)</span>
</code></pre></div></p>
<h3 id="3-lm-studio-openai-compatible-easy-setup">3. LM Studio (OpenAI-Compatible) - EASY SETUP<a class="headerlink" href="#3-lm-studio-openai-compatible-easy-setup" title="Permanent link">&para;</a></h3>
<p><strong>Requirements:</strong>
- macOS/Windows/Linux
- LM Studio desktop app</p>
<p><strong>Installation:</strong>
1. Download LM Studio from <a href="https://lmstudio.ai/">lmstudio.ai</a>
2. Install and launch the application
3. Go to "Models" tab and search for:
   - <code>llama-3.2-1b-instruct</code>
   - <code>llama-3.2-3b-instruct</code>
4. Download desired models
5. Go to "Server" tab and start local server (default: localhost:1234)</p>
<p><strong>Configuration:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="c1"># In your .env file</span>
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="nv">LMSTUDIO_ENABLED</span><span class="o">=</span><span class="nb">true</span>
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="nv">LMSTUDIO_API_URL</span><span class="o">=</span>http://localhost:1234/v1
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a><span class="nv">LMSTUDIO_MODEL</span><span class="o">=</span>llama-3.2-1b-instruct
</code></pre></div></p>
<h2 id="performance-testing">Performance Testing<a class="headerlink" href="#performance-testing" title="Permanent link">&para;</a></h2>
<h3 id="automated-benchmark">Automated Benchmark<a class="headerlink" href="#automated-benchmark" title="Permanent link">&para;</a></h3>
<p>Run the comprehensive benchmark script:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="c1"># Test all providers</span>
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>python<span class="w"> </span>scripts/benchmark_llm_providers.py
<a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>
<a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a><span class="c1"># Test specific provider</span>
<a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>python<span class="w"> </span>scripts/benchmark_llm_providers.py<span class="w"> </span>--provider<span class="w"> </span>mlx
<a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>
<a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a><span class="c1"># Quick test (fewer prompts)</span>
<a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>python<span class="w"> </span>scripts/benchmark_llm_providers.py<span class="w"> </span>--quick
</code></pre></div>
<h3 id="manual-testing">Manual Testing<a class="headerlink" href="#manual-testing" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Web UI Testing:</strong></li>
<li>Go to Settings page</li>
<li>Select provider from dropdown</li>
<li>Click "Test Connection" button</li>
<li>
<p>Verify successful connection</p>
</li>
<li>
<p><strong>RAG Chat Testing:</strong></p>
</li>
<li>Go to RAG Chat page</li>
<li>Select provider from dropdown</li>
<li>Ask threat intelligence questions</li>
<li>Compare response times and quality</li>
</ol>
<h3 id="benchmark-results">Benchmark Results<a class="headerlink" href="#benchmark-results" title="Permanent link">&para;</a></h3>
<p>The benchmark script generates:
- <strong>Terminal output:</strong> Real-time progress and summary table
- <strong>JSON results:</strong> <code>logs/llm_benchmark_results_TIMESTAMP.json</code>
- <strong>Markdown report:</strong> <code>logs/LLM_BENCHMARK_REPORT_TIMESTAMP.md</code></p>
<h2 id="configuration-guide">Configuration Guide<a class="headerlink" href="#configuration-guide" title="Permanent link">&para;</a></h2>
<h3 id="environment-variables_1">Environment Variables<a class="headerlink" href="#environment-variables_1" title="Permanent link">&para;</a></h3>
<p>Add to your <code>.env</code> file:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="c1"># Performance Testing - Local LLM Providers</span>
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="nv">LMSTUDIO_API_URL</span><span class="o">=</span>http://localhost:1234/v1
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="nv">LMSTUDIO_MODEL</span><span class="o">=</span>llama-3.2-1b-instruct
<a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a><span class="nv">LMSTUDIO_ENABLED</span><span class="o">=</span><span class="nb">false</span>
<a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a><span class="c1"># Docker: Use http://host.docker.internal:1234/v1 (default in Docker).</span>
<a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a><span class="c1"># Use http://localhost:1234/v1 only for non-Docker local development.</span>
<a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a>
<a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a><span class="nv">MLX_MODEL_PATH</span><span class="o">=</span>models/mlx/llama-3.2-1b-instruct
<a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a><span class="nv">MLX_ENABLED</span><span class="o">=</span><span class="nb">false</span>
<a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a>
<a id="__codelineno-10-11" name="__codelineno-10-11" href="#__codelineno-10-11"></a><span class="nv">LLAMACPP_MODEL_PATH</span><span class="o">=</span>models/gguf/llama-3.2-1b-instruct.gguf
<a id="__codelineno-10-12" name="__codelineno-10-12" href="#__codelineno-10-12"></a><span class="nv">LLAMACPP_SERVER_URL</span><span class="o">=</span>http://localhost:8080
<a id="__codelineno-10-13" name="__codelineno-10-13" href="#__codelineno-10-13"></a><span class="nv">LLAMACPP_ENABLED</span><span class="o">=</span><span class="nb">false</span>
</code></pre></div>
<h3 id="provider-selection">Provider Selection<a class="headerlink" href="#provider-selection" title="Permanent link">&para;</a></h3>
<p>The system uses an intelligent fallback chain:</p>
<ol>
<li><strong>MLX</strong> (if enabled and available)</li>
<li><strong>llama.cpp</strong> (if enabled and available)</li>
<li><strong>LM Studio</strong> (if enabled and available)</li>
<li><strong>Cloud APIs</strong> (OpenAI/Anthropic)</li>
</ol>
<h2 id="troubleshooting_1">Troubleshooting<a class="headerlink" href="#troubleshooting_1" title="Permanent link">&para;</a></h2>
<h3 id="common-issues">Common Issues<a class="headerlink" href="#common-issues" title="Permanent link">&para;</a></h3>
<p><strong>MLX Issues:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="c1"># Error: MLX not installed</span>
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>pip<span class="w"> </span>install<span class="w"> </span>mlx-lm
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a><span class="c1"># Error: Model not found</span>
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>./scripts/setup_local_models.sh<span class="w"> </span>--with-mlx<span class="w"> </span>llama-3.2-1b-instruct
<a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>
<a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a><span class="c1"># Error: Metal backend not available</span>
<a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a><span class="c1"># Ensure you&#39;re on Apple Silicon Mac</span>
</code></pre></div></p>
<p><strong>llama.cpp Issues:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="c1"># Error: llama-cpp-python not installed</span>
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>pip<span class="w"> </span>install<span class="w"> </span>llama-cpp-python
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>
<a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a><span class="c1"># Error: GGUF model not found</span>
<a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>./scripts/setup_local_models.sh<span class="w"> </span>--with-llamacpp<span class="w"> </span>llama-3.2-1b-instruct
<a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>
<a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a><span class="c1"># Error: Metal backend compilation failed</span>
<a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a><span class="c1"># Reinstall with Metal support</span>
<a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a><span class="nv">CMAKE_ARGS</span><span class="o">=</span><span class="s2">&quot;-DGGML_METAL=on&quot;</span><span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>llama-cpp-python<span class="w"> </span>--force-reinstall
</code></pre></div></p>
<p><strong>LM Studio Issues:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="c1"># Error: Cannot connect to LM Studio</span>
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a><span class="c1"># 1. Ensure LM Studio is running</span>
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a><span class="c1"># 2. Check server is started (Server tab)</span>
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a><span class="c1"># 3. Verify port 1234 is not blocked</span>
<a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a><span class="c1"># 4. Check LMSTUDIO_API_URL in .env</span>
<a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>
<a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a><span class="c1"># Error: Model not loaded</span>
<a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a><span class="c1"># 1. Go to Models tab in LM Studio</span>
<a id="__codelineno-13-9" name="__codelineno-13-9" href="#__codelineno-13-9"></a><span class="c1"># 2. Load the model you want to use</span>
<a id="__codelineno-13-10" name="__codelineno-13-10" href="#__codelineno-13-10"></a><span class="c1"># 3. Ensure model name matches LMSTUDIO_MODEL</span>
</code></pre></div></p>
<h3 id="performance-optimization">Performance Optimization<a class="headerlink" href="#performance-optimization" title="Permanent link">&para;</a></h3>
<p><strong>MLX Optimization:</strong>
- Use 4-bit quantized models for best speed/memory balance
- Ensure sufficient RAM (8GB+ recommended for 7B models)
- Close other GPU-intensive applications</p>
<p><strong>llama.cpp Optimization:</strong>
- Use <code>n_gpu_layers=-1</code> to utilize all Metal layers
- Adjust <code>n_ctx</code> based on your use case (higher = more memory)
- Use GGUF format for best compatibility</p>
<p><strong>LM Studio Optimization:</strong>
- Use GPU acceleration in LM Studio settings
- Load models into GPU memory when possible
- Close unnecessary applications to free GPU memory</p>
<h3 id="memory-requirements">Memory Requirements<a class="headerlink" href="#memory-requirements" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Model Size</th>
<th>MLX RAM</th>
<th>llama.cpp RAM</th>
<th>LM Studio RAM</th>
</tr>
</thead>
<tbody>
<tr>
<td>1B</td>
<td>2-3GB</td>
<td>2-3GB</td>
<td>2-3GB</td>
</tr>
<tr>
<td>3B</td>
<td>4-6GB</td>
<td>4-6GB</td>
<td>4-6GB</td>
</tr>
<tr>
<td>7B</td>
<td>8-12GB</td>
<td>8-12GB</td>
<td>8-12GB</td>
</tr>
</tbody>
</table>
<h2 id="model-recommendations">Model Recommendations<a class="headerlink" href="#model-recommendations" title="Permanent link">&para;</a></h2>
<h3 id="for-maximum-speed-apple-silicon">For Maximum Speed (Apple Silicon)<a class="headerlink" href="#for-maximum-speed-apple-silicon" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>MLX</strong> with 1B model: 2-3 second responses</li>
<li><strong>llama.cpp</strong> with 1B model: 2-4 second responses</li>
<li><strong>LM Studio</strong> with 1B model: 3-5 second responses</li>
</ol>
<h3 id="for-best-qualityspeed-balance">For Best Quality/Speed Balance<a class="headerlink" href="#for-best-qualityspeed-balance" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>MLX</strong> with 3B model: 4-6 second responses</li>
<li><strong>llama.cpp</strong> with 3B model: 5-8 second responses</li>
<li><strong>LM Studio</strong> with 3B model: 6-10 second responses</li>
</ol>
<h3 id="for-maximum-quality">For Maximum Quality<a class="headerlink" href="#for-maximum-quality" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>MLX</strong> with 7B model: 8-12 second responses</li>
<li><strong>llama.cpp</strong> with 7B model: 10-15 second responses</li>
<li><strong>LM Studio</strong> with 7B model: 12-20 second responses</li>
</ol>
<h2 id="integration-with-cti-scraper">Integration with CTI Scraper<a class="headerlink" href="#integration-with-cti-scraper" title="Permanent link">&para;</a></h2>
<h3 id="rag-system-integration">RAG System Integration<a class="headerlink" href="#rag-system-integration" title="Permanent link">&para;</a></h3>
<p>The local LLM providers integrate seamlessly with the RAG system:</p>
<ol>
<li><strong>Provider Selection:</strong> Choose provider in Settings or use auto-selection</li>
<li><strong>Fallback Chain:</strong> Automatic fallback if primary provider fails</li>
<li><strong>Context Management:</strong> All providers use the same conversation context</li>
<li><strong>Response Format:</strong> Consistent response format across all providers</li>
</ol>
<h3 id="api-integration">API Integration<a class="headerlink" href="#api-integration" title="Permanent link">&para;</a></h3>
<p>All providers expose the same API interface:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="c1"># Example usage</span>
<a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">src.services.llm_generation_service</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_llm_generation_service</span>
<a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a>
<a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a><span class="n">service</span> <span class="o">=</span> <span class="n">get_llm_generation_service</span><span class="p">()</span>
<a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a>
<a id="__codelineno-14-6" name="__codelineno-14-6" href="#__codelineno-14-6"></a><span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="n">service</span><span class="o">.</span><span class="n">generate_rag_response</span><span class="p">(</span>
<a id="__codelineno-14-7" name="__codelineno-14-7" href="#__codelineno-14-7"></a>    <span class="n">query</span><span class="o">=</span><span class="s2">&quot;Analyze this threat intelligence&quot;</span><span class="p">,</span>
<a id="__codelineno-14-8" name="__codelineno-14-8" href="#__codelineno-14-8"></a>    <span class="n">retrieved_chunks</span><span class="o">=</span><span class="n">chunks</span><span class="p">,</span>
<a id="__codelineno-14-9" name="__codelineno-14-9" href="#__codelineno-14-9"></a>    <span class="n">provider</span><span class="o">=</span><span class="s2">&quot;mlx&quot;</span>  <span class="c1"># or &quot;auto&quot; for automatic selection</span>
<a id="__codelineno-14-10" name="__codelineno-14-10" href="#__codelineno-14-10"></a><span class="p">)</span>
</code></pre></div>
<h2 id="best-practices">Best Practices<a class="headerlink" href="#best-practices" title="Permanent link">&para;</a></h2>
<ol>
<li><strong>Start with MLX</strong> for maximum Apple Silicon performance</li>
<li><strong>Use llama.cpp</strong> as backup for compatibility</li>
<li><strong>Keep LM Studio</strong> for easy model management</li>
<li><strong>Test thoroughly</strong> with the benchmark script</li>
<li><strong>Monitor memory usage</strong> during extended use</li>
<li><strong>Update models regularly</strong> for security and performance</li>
</ol>
<h2 id="support">Support<a class="headerlink" href="#support" title="Permanent link">&para;</a></h2>
<p>For issues or questions:
1. Check this documentation first
2. Run the benchmark script for diagnostics
3. Check the logs in <code>logs/</code> directory
4. Verify environment variables and model paths
5. Test individual providers in the web UI</p>
<hr />
<p><strong>Note:</strong> Currently only LM Studio is implemented as an active local provider. MLX and llama.cpp are planned for future releases.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["content.code.copy", "navigation.tabs", "navigation.sections", "navigation.expand", "toc.integrate"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>