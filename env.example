# Environment Configuration for CTI Scraper
# Copy this file to .env and fill in your actual values

# Database Configuration
DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
POSTGRES_DB=cti_scraper
POSTGRES_USER=your_postgres_user
POSTGRES_PASSWORD=your_secure_postgres_password
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# Redis Configuration
REDIS_URL=redis://:${REDIS_PASSWORD}@${REDIS_HOST}:${REDIS_PORT}/${REDIS_DB}
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=your_secure_redis_password
REDIS_DB=0

# Application Configuration
ENVIRONMENT=production
LOG_LEVEL=INFO
DEBUG=false
SECRET_KEY=your-super-secret-key-change-this-in-production
ALLOWED_HOSTS=localhost,127.0.0.1,0.0.0.0

# Web Server Configuration
HOST=0.0.0.0
PORT=8000
WORKERS=4
RELOAD=false

# Security Configuration
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8000"]
TRUSTED_HOSTS=["localhost", "127.0.0.1", "0.0.0.0"]

# Rate Limiting
RATE_LIMIT_PER_MINUTE=100
API_RATE_LIMIT_PER_MINUTE=30

# Database Pool Configuration
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=30
DB_POOL_PRE_PING=true
DB_POOL_RECYCLE=3600

# Celery Configuration
CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@${REDIS_HOST}:${REDIS_PORT}/${REDIS_DB}
CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@${REDIS_HOST}:${REDIS_PORT}/${REDIS_DB}
CELERY_TASK_ALWAYS_EAGER=false
CELERY_WORKER_CONCURRENCY=4

# Monitoring and Logging
ENABLE_METRICS=true
METRICS_PORT=9090
LOG_FORMAT=json
LOG_FILE=logs/cti_scraper.log

# Content Processing
MAX_CONTENT_LENGTH=10485760  # 10MB
CONTENT_CLEANUP_ENABLED=true
GARBAGE_DETECTION_ENABLED=true

# Source Configuration
DEFAULT_CHECK_FREQUENCY=3600  # 1 hour
TIER1_CHECK_FREQUENCY=900     # 15 minutes
MAX_CONSECUTIVE_FAILURES=5

# LLM Configuration (Optional)
LLM_API_URL=http://ollama:11434
LLM_MODEL=mistral
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=2048
OLLAMA_CONTENT_LIMIT=8000  # Max characters to send to Ollama (conservative for local models)

# ChatGPT Configuration (Optional - falls back to Ollama if not set)
CHATGPT_API_URL=https://api.openai.com/v1/chat/completions
CHATGPT_API_KEY=your_openai_api_key_here
CHATGPT_CONTENT_LIMIT=20000  # Max characters to send to ChatGPT (GPT-4: 20000, GPT-4-Turbo: 50000, GPT-3.5: 15000)

# CustomGPT Configuration (Optional - for threat hunting analysis)
CUSTOMGPT_API_URL=https://api.openai.com/v1
CUSTOMGPT_API_KEY=your-customgpt-api-key-here

# Hugging Face Hub Configuration (for fine-tuning)
HF_TOKEN=your_huggingface_token_here


# AWS Configuration (for deployment)
AWS_ACCESS_KEY_ID=your_aws_access_key_here
AWS_SECRET_ACCESS_KEY=your_aws_secret_key_here
AWS_DEFAULT_REGION=us-east-1

# Fine-tuning Configuration
FINE_TUNE_OUTPUT_DIR=./models
FINE_TUNE_EPOCHS=3
FINE_TUNE_LEARNING_RATE=5e-5
FINE_TUNE_BATCH_SIZE=2
FINE_TUNE_GRADIENT_ACCUMULATION_STEPS=4

# LM Studio Configuration (Optional - for local LLM)
LMSTUDIO_API_URL=http://localhost:1234/v1
LMSTUDIO_API_KEY=lm-studio
LMSTUDIO_MODEL_NAME=your-model-name

# Content Filtering and Scoring
THREAT_HUNTING_KEYWORDS_ENABLED=true
PERFECT_DISCRIMINATOR_ENABLED=true
CONTENT_FILTER_ENABLED=true

# Backup and Recovery
BACKUP_ENABLED=true
BACKUP_RETENTION_DAYS=30
BACKUP_SCHEDULE=0 2 * * *  # Daily at 2 AM

# Performance Tuning
MAX_WORKERS=8
WORKER_TIMEOUT=300
REQUEST_TIMEOUT=30

# Development Settings (set to false in production)
DEVELOPMENT_MODE=false
ENABLE_DEBUG_ROUTES=false
ENABLE_PROFILING=false