{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTI Fine-tuning Backend with Hugging Face Hub Integration\n",
    "# This notebook runs in Colab with GPU access using shared training functions\n",
    "!pip install transformers datasets torch accelerate huggingface_hub\n",
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add shared training module to path\n",
    "sys.path.append('/content')\n",
    "\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code", 
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import shared training module\n",
    "from shared_training import FineTuningTrainer, AVAILABLE_MODELS, create_training_data_from_csv, setup_huggingface_hub\n",
    "\n",
    "# Initialize trainer for Colab GPU environment\n",
    "trainer = FineTuningTrainer(device=\"cuda\")\n",
    "\n",
    "print(\"‚úÖ Shared training module loaded\")\n",
    "print(f\"Available models: {len(AVAILABLE_MODELS)}\")\n",
    "print(\"\\nColab-compatible models:\")\n",
    "for model_id, info in AVAILABLE_MODELS.items():\n",
    "    if info.get('location') == 'colab':\n",
    "        print(f\"- {info['name']}: {info['size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Hugging Face Hub authentication\n",
    "print(\"üîê Setting up Hugging Face Hub authentication...\")\n",
    "hf_ready = setup_huggingface_hub()\n",
    "\n",
    "if hf_ready:\n",
    "    print(\"‚úÖ Hugging Face Hub ready - can push models\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Hugging Face Hub not configured - models will be saved locally only\")\n",
    "    print(\"To enable Hub features, set HF_TOKEN environment variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function using shared module with Hub support\n",
    "def fine_tune_model_colab(model_name, training_data, epochs=3, learning_rate=5e-5, push_to_hub=False, hub_model_id=None):\n",
    "    \"\"\"Fine-tune model using shared training module optimized for Colab GPU\"\"\"\n",
    "    print(f'Starting Colab GPU fine-tuning for {model_name}')\n",
    "    print(f'Training examples: {len(training_data)}')\n",
    "    \n",
    "    if push_to_hub and hub_model_id:\n",
    "        print(f'Will push to Hugging Face Hub as: {hub_model_id}')\n",
    "    \n",
    "    # Use shared trainer with GPU optimizations\n",
    "    trainer_result, output_dir = trainer.fine_tune_model(\n",
    "        model_name,\n",
    "        training_data,\n",
    "        epochs=epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        output_dir=\"./models\",\n",
    "        push_to_hub=push_to_hub,\n",
    "        hub_model_id=hub_model_id\n",
    "    )\n",
    "    \n",
    "    print(f'Colab GPU training completed! Model saved to: {output_dir}')\n",
    "    if push_to_hub and hub_model_id:\n",
    "        print(f'Model also available on Hugging Face Hub: {hub_model_id}')\n",
    "    \n",
    "    return trainer_result, output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function using shared module\n",
    "def test_fine_tuned_model_colab(model_path, test_prompt):\n",
    "    \"\"\"Test the fine-tuned model using shared module\"\"\"\n",
    "    return trainer.test_fine_tuned_model(model_path, test_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "print(\"üöÄ Colab Fine-tuning Backend Ready!\")\n",
    "print(\"\\nUsage:\")\n",
    "print(\"1. Prepare training data as list of {'input': '...', 'output': '...'} dictionaries\")\n",
    "print(\"2. Call fine_tune_model_colab(model_name, training_data, epochs, learning_rate, push_to_hub, hub_model_id)\")\n",
    "print(\"3. Test with test_fine_tuned_model_colab(model_path, test_prompt)\")\n",
    "print(\"\\nExample:\")\n",
    "print(\"training_data = [{'input': 'Attackers ran powershell.exe', 'output': 'SIGMA rule...'}]\")\n",
    "print(\"trainer_result, output_dir = fine_tune_model_colab('microsoft/Phi-3-mini-4k-instruct', training_data)\")\n",
    "print(\"\\nWith Hub push:\")\n",
    "print(\"trainer_result, output_dir = fine_tune_model_colab('microsoft/Phi-3-mini-4k-instruct', training_data, push_to_hub=True, hub_model_id='username/my-cti-model')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
