{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Testing Notebook\n",
    "\n",
    "This notebook allows you to test each agent in the workflow individually with editable prompts.\n",
    "\n",
    "## Workflow Steps:\n",
    "0. **Junk Filter** - Filters content using ContentFilter\n",
    "1. **LLM Rank Article** - Ranks article for huntability (1-10)\n",
    "2. **Extract Agent** - Extracts behavioral observables and IOCs\n",
    "3. **Generate SIGMA** - Generates SIGMA detection rules\n",
    "4. **Similarity Search** - Searches for similar existing rules\n",
    "5. **Promote to Queue** - Promotes rules to queue if similarity is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable text wrapping in notebook output and code cellsfrom IPython.display import HTML, displaydisplay(HTML(\"\"\"<style>    /* Wrap output text */    .output_text {        white-space: pre-wrap !important;        word-wrap: break-word !important;        overflow-wrap: break-word !important;    }    .jp-OutputArea-output {        white-space: pre-wrap !important;        word-wrap: break-word !important;        overflow-wrap: break-word !important;    }    pre {        white-space: pre-wrap !important;        word-wrap: break-word !important;        overflow-wrap: break-word !important;    }    .jp-CodeCell-output pre {        white-space: pre-wrap !important;        word-wrap: break-word !important;    }        /* Wrap code cell source */    .CodeMirror-line {        white-space: pre-wrap !important;        word-wrap: break-word !important;        overflow-wrap: break-word !important;    }    .jp-CodeMirror-editor {        white-space: pre-wrap !important;        word-wrap: break-word !important;    }    .CodeMirror {        word-wrap: break-word !important;        overflow-wrap: break-word !important;    }        /* Wrap in classic notebook */    .input_area {        white-space: pre-wrap !important;        word-wrap: break-word !important;    }    .CodeMirror-lines {        white-space: pre-wrap !important;        word-wrap: break-word !important;    }</style>\"\"\"))print(\"‚úÖ Text wrapping enabled for notebook output and code cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install missing dependenciesimport sysimport subprocessimport importlibdef install_package(package):    # Try --user first, fallback to --break-system-packages if needed    try:        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package, '--user', '--quiet'],                              stderr=subprocess.DEVNULL)    except subprocess.CalledProcessError:        # Fallback for environments that don't support --user        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package, '--quiet', '--break-system-packages'],                             stderr=subprocess.DEVNULL)# Install and import pgvectortry:    import pgvector    print('‚úÖ pgvector already installed')except ImportError:    print('‚ö†Ô∏è  Installing pgvector...')    install_package('pgvector')    # Invalidate caches and re-import    importlib.invalidate_caches()    import pgvector    print('‚úÖ pgvector installed and imported')# Install and import sqlalchemytry:    import sqlalchemy    print('‚úÖ sqlalchemy already installed')except ImportError:    print('‚ö†Ô∏è  Installing sqlalchemy...')    install_package('sqlalchemy')    importlib.invalidate_caches()    import sqlalchemy    print('‚úÖ sqlalchemy installed and imported')# Install and import sentence_transformerstry:    import sentence_transformers    print('‚úÖ sentence_transformers already installed')except ImportError:    print('‚ö†Ô∏è  Installing sentence_transformers...')    install_package('sentence_transformers')    importlib.invalidate_caches()    import sentence_transformers    print('‚úÖ sentence_transformers installed and imported')# Final cache invalidation to ensure all imports workimportlib.invalidate_caches()print('‚úÖ Import caches invalidated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded environment variables from .env\n",
      "‚úÖ sentence_transformers already installed\n",
      "‚úÖ Services initialized\n",
      "   Ranking Model: deepseek/deepseek-r1-0528-qwen3-8b\n",
      "   Extraction Model: deepseek/deepseek-r1-0528-qwen3-8b\n",
      "   SIGMA Model: deepseek/deepseek-r1-0528-qwen3-8b\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import asyncio\n",
    "from typing import Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Try to load .env file if python-dotenv is available\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    env_path = Path('.env')\n",
    "    if env_path.exists():\n",
    "        load_dotenv(env_path)\n",
    "        print(\"‚úÖ Loaded environment variables from .env\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No .env file found, using system environment variables\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  python-dotenv not installed, using system environment variables only\")\n",
    "    print(\"   Install with: pip install python-dotenv\")\n",
    "\n",
    "# Set default LMStudio model values if not already set\n",
    "# These can be overridden by setting environment variables\n",
    "if not os.getenv('LMSTUDIO_MODEL_RANK'):\n",
    "    default_model = os.getenv('LMSTUDIO_MODEL', 'mistralai/mistral-7b-instruct-v0.3')\n",
    "    os.environ['LMSTUDIO_MODEL_RANK'] = default_model\n",
    "    print(f\"‚ö†Ô∏è  LMSTUDIO_MODEL_RANK not set, using: {os.environ['LMSTUDIO_MODEL_RANK']}\")\n",
    "\n",
    "if not os.getenv('LMSTUDIO_MODEL_EXTRACT'):\n",
    "    default_model = os.getenv('LMSTUDIO_MODEL', 'mistralai/mistral-7b-instruct-v0.3')\n",
    "    os.environ['LMSTUDIO_MODEL_EXTRACT'] = default_model\n",
    "    \n",
    "if not os.getenv('LMSTUDIO_MODEL_SIGMA'):\n",
    "    default_model = os.getenv('LMSTUDIO_MODEL', 'mistralai/mistral-7b-instruct-v0.3')\n",
    "    os.environ['LMSTUDIO_MODEL_SIGMA'] = default_model\n",
    "\n",
    "if not os.getenv('LMSTUDIO_API_URL'):\n",
    "    os.environ['LMSTUDIO_API_URL'] = 'http://localhost:1234/v1'\n",
    "    print(f\"‚ö†Ô∏è  LMSTUDIO_API_URL not set, using: {os.environ['LMSTUDIO_API_URL']}\")\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Database and workflow imports\n",
    "from src.database.async_manager import AsyncDatabaseManager\n",
    "from src.database.models import ArticleTable\n",
    "from src.utils.content_filter import ContentFilter\n",
    "from src.services.llm_service import LLMService\n",
    "from src.services.sigma_generation_service import SigmaGenerationService\n",
    "# Install sentence_transformers if needed\n",
    "try:\n",
    "    import sentence_transformers\n",
    "    print('‚úÖ sentence_transformers already installed')\n",
    "except ImportError:\n",
    "    import sys\n",
    "    import subprocess\n",
    "    print('‚ö†Ô∏è Installing sentence_transformers...')\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'sentence_transformers', '--user', '--quiet'], stderr=subprocess.DEVNULL)\n",
    "    except subprocess.CalledProcessError:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'sentence_transformers', '--quiet', '--break-system-packages'], stderr=subprocess.DEVNULL)\n",
    "    import importlib\n",
    "    importlib.invalidate_caches()\n",
    "    import sentence_transformers\n",
    "    print('‚úÖ sentence_transformers installed')\n",
    "\n",
    "from src.services.rag_service import RAGService\n",
    "\n",
    "# Initialize services\n",
    "async_db_manager = AsyncDatabaseManager()\n",
    "llm_service = LLMService()\n",
    "content_filter = ContentFilter()\n",
    "sigma_service = SigmaGenerationService()\n",
    "rag_service = RAGService()\n",
    "\n",
    "print(\"‚úÖ Services initialized\")\n",
    "print(f\"   Ranking Model: {llm_service.model_rank}\")\n",
    "print(f\"   Extraction Model: {llm_service.model_extract}\")\n",
    "print(f\"   SIGMA Model: {llm_service.model_sigma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Configuration:\n",
      "   Article ID: 2042\n",
      "   Junk Filter Threshold: 0.8\n",
      "   Ranking Threshold: 6.0\n"
     ]
    }
   ],
   "source": [
    "# Configuration - Edit these values\n",
    "ARTICLE_ID = 2042  # Change this to test different articles\n",
    "JUNK_FILTER_THRESHOLD = 0.8  # Confidence threshold for junk filter\n",
    "RANKING_THRESHOLD = 6.0  # Minimum ranking score to continue\n",
    "\n",
    "# Model selection\n",
    "RANKING_MODEL = 'lmstudio'  # Model for ranking\n",
    "EXTRACTION_MODEL = 'lmstudio'  # Model for extraction\n",
    "SIGMA_MODEL = 'lmstudio'  # Model for SIGMA generation\n",
    "\n",
    "print(f\"üìã Configuration:\")\n",
    "print(f\"   Article ID: {ARTICLE_ID}\")\n",
    "print(f\"   Junk Filter Threshold: {JUNK_FILTER_THRESHOLD}\")\n",
    "print(f\"   Ranking Threshold: {RANKING_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database session error: [Errno 8] nodename nor servname provided, or not known\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/starlord/CTIScraper/src/database/async_manager.py\", line 85, in get_session\n",
      "    yield session\n",
      "  File \"/Users/starlord/CTIScraper/src/database/async_manager.py\", line 709, in get_article\n",
      "    result = await session.execute(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/ext/asyncio/session.py\", line 454, in execute\n",
      "    result = await greenlet_spawn(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py\", line 190, in greenlet_spawn\n",
      "    result = context.throw(*sys.exc_info())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/orm/session.py\", line 2262, in execute\n",
      "    return self._execute_internal(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/orm/session.py\", line 2134, in _execute_internal\n",
      "    conn = self._connection_for_bind(bind)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/orm/session.py\", line 2001, in _connection_for_bind\n",
      "    return trans._connection_for_bind(engine, execution_options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 2, in _connection_for_bind\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py\", line 139, in _go\n",
      "    ret_value = fn(self, *arg, **kw)\n",
      "                ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/orm/session.py\", line 1126, in _connection_for_bind\n",
      "    conn = bind.connect()\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 3264, in connect\n",
      "    return self._connection_cls(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 145, in __init__\n",
      "    self._dbapi_connection = engine.raw_connection()\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 3288, in raw_connection\n",
      "    return self.pool.connect()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 452, in connect\n",
      "    return _ConnectionFairy._checkout(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 1267, in _checkout\n",
      "    fairy = _ConnectionRecord.checkout(pool)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 716, in checkout\n",
      "    rec = pool._do_get()\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/pool/impl.py\", line 169, in _do_get\n",
      "    with util.safe_reraise():\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py\", line 147, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/pool/impl.py\", line 167, in _do_get\n",
      "    return self._create_connection()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 393, in _create_connection\n",
      "    return _ConnectionRecord(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 678, in __init__\n",
      "    self.__connect()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 902, in __connect\n",
      "    with util.safe_reraise():\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py\", line 147, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 898, in __connect\n",
      "    self.dbapi_connection = connection = pool._invoke_creator(self)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/engine/create.py\", line 637, in connect\n",
      "    return dialect.connect(*cargs, **cparams)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/engine/default.py\", line 615, in connect\n",
      "    return self.loaded_dbapi.connect(*cargs, **cparams)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py\", line 917, in connect\n",
      "    await_only(creator_fn(*arg, **kw)),\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py\", line 125, in await_only\n",
      "    return current.driver.switch(awaitable)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py\", line 185, in greenlet_spawn\n",
      "    value = await result\n",
      "            ^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/asyncpg/connection.py\", line 2421, in connect\n",
      "    return await connect_utils._connect(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/asyncpg/connect_utils.py\", line 1075, in _connect\n",
      "    raise last_error or exceptions.TargetServerAttributeNotMatched(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/asyncpg/connect_utils.py\", line 1049, in _connect\n",
      "    conn = await _connect_addr(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/asyncpg/connect_utils.py\", line 886, in _connect_addr\n",
      "    return await __connect_addr(params, True, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/asyncpg/connect_utils.py\", line 931, in __connect_addr\n",
      "    tr, pr = await connector\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/asyncpg/connect_utils.py\", line 802, in _create_ssl_connection\n",
      "    tr, pr = await loop.create_connection(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1045, in create_connection\n",
      "    infos = await self._ensure_resolved(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1419, in _ensure_resolved\n",
      "    return await loop.getaddrinfo(host, port, family=family, type=type,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 867, in getaddrinfo\n",
      "    return await self.run_in_executor(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py\", line 962, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "socket.gaierror: [Errno 8] nodename nor servname provided, or not known\n",
      "Failed to get article 2042: [Errno 8] nodename nor servname provided, or not known\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Article 2042 not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 21\u001b[0m\n\u001b[1;32m      8\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m async_db_manager\u001b[38;5;241m.\u001b[39mget_source(article\u001b[38;5;241m.\u001b[39msource_id)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: article\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: article\u001b[38;5;241m.\u001b[39mtitle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m: article\u001b[38;5;241m.\u001b[39marticle_metadata\n\u001b[1;32m     19\u001b[0m     }\n\u001b[0;32m---> 21\u001b[0m article \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m load_article(ARTICLE_ID)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Loaded Article \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mARTICLE_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marticle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m][:\u001b[38;5;241m80\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Content length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(article[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m characters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m, in \u001b[0;36mload_article\u001b[0;34m(article_id)\u001b[0m\n\u001b[1;32m      4\u001b[0m article \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m async_db_manager\u001b[38;5;241m.\u001b[39mget_article(article_id)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m article:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArticle \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marticle_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m async_db_manager\u001b[38;5;241m.\u001b[39mget_source(article\u001b[38;5;241m.\u001b[39msource_id)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: article\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: article\u001b[38;5;241m.\u001b[39mtitle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m: article\u001b[38;5;241m.\u001b[39marticle_metadata\n\u001b[1;32m     19\u001b[0m }\n",
      "\u001b[0;31mValueError\u001b[0m: Article 2042 not found"
     ]
    }
   ],
   "source": [
    "# Load article\n",
    "async def load_article(article_id: int):\n",
    "    \"\"\"Load article from database.\"\"\"\n",
    "    article = await async_db_manager.get_article(article_id)\n",
    "    if not article:\n",
    "        raise ValueError(f\"Article {article_id} not found\")\n",
    "    \n",
    "    source = await async_db_manager.get_source(article.source_id)\n",
    "    \n",
    "    return {\n",
    "        'id': article.id,\n",
    "        'title': article.title,\n",
    "        'content': article.content,\n",
    "        'source_id': article.source_id,\n",
    "        'source_name': source.name if source else 'Unknown',\n",
    "        'url': article.canonical_url or '',\n",
    "        'published_at': article.published_at,\n",
    "        'metadata': article.article_metadata\n",
    "    }\n",
    "\n",
    "article = await load_article(ARTICLE_ID)\n",
    "print(f\"‚úÖ Loaded Article {ARTICLE_ID}: {article['title'][:80]}...\")\n",
    "print(f\"   Content length: {len(article['content'])} characters\")\n",
    "print(f\"   Source: {article['source_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Junk Filter\n",
    "\n",
    "Filters content using ContentFilter to remove junk/non-huntable content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Junk Filter\n",
    "async def test_junk_filter(content: str, threshold: float = 0.8, article_id: int = None):\n",
    "    \"\"\"Test junk filter step.\"\"\"\n",
    "    print(\"üîç Running Junk Filter...\")\n",
    "    \n",
    "    hunt_score = article.get('metadata', {}).get('threat_hunting_score', 0) if article else 0\n",
    "    \n",
    "    filter_result = content_filter.filter_content(\n",
    "        content,\n",
    "        min_confidence=threshold,\n",
    "        hunt_score=hunt_score,\n",
    "        article_id=article_id or ARTICLE_ID\n",
    "    )\n",
    "    \n",
    "    result = {\n",
    "        'filtered': filter_result.is_huntable,\n",
    "        'confidence': filter_result.confidence,\n",
    "        'original_length': len(content),\n",
    "        'filtered_length': len(filter_result.filtered_content) if filter_result.filtered_content else 0,\n",
    "        'filtered_content': filter_result.filtered_content or content,\n",
    "        'chunks_removed': len(filter_result.removed_chunks) if filter_result.removed_chunks else 0\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Junk Filter Result:\")\n",
    "    print(f\"   Filtered (is_huntable): {result['filtered']}\")\n",
    "    print(f\"   Confidence: {result['confidence']:.3f}\")\n",
    "    print(f\"   Original length: {result['original_length']:,} chars\")\n",
    "    print(f\"   Filtered length: {result['filtered_length']:,} chars\")\n",
    "    print(f\"   Chunks removed: {result['chunks_removed']}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run junk filter\n",
    "junk_filter_result = await test_junk_filter(\n",
    "    article['content'],\n",
    "    threshold=JUNK_FILTER_THRESHOLD,\n",
    "    article_id=ARTICLE_ID\n",
    ")\n",
    "\n",
    "# Store filtered content for next steps\n",
    "filtered_content = junk_filter_result['filtered_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: LLM Rank Article\n",
    "\n",
    "Ranks the article for huntability. **Edit the prompt below** to customize ranking behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editable Ranking Prompt\n",
    "RANKING_PROMPT = \"\"\"As a cybersecurity expert specializing in threat hunting and detection engineering, analyze this threat intelligence article for its usefulness to security professionals.\n",
    "\n",
    "**Article Title:** {title}\n",
    "**Source:** {source}\n",
    "**URL:** {url}\n",
    "**Content Length:** {content_length} characters\n",
    "\n",
    "**Analysis Criteria:**\n",
    "1. **Technical Depth:** Does the article provide specific technical details, commands, or procedures?\n",
    "2. **Actionable Intelligence:** Can security teams immediately act on this information?\n",
    "3. **Detection Potential:** Does it contain indicators or behaviors that can be detected?\n",
    "4. **Threat Hunting Value:** Is this useful for proactive threat hunting activities?\n",
    "5. **Operational Impact:** How relevant is this for day-to-day security operations?\n",
    "\n",
    "**Scoring Guidelines:**\n",
    "- **9-10:** Excellent - Highly actionable, specific technical details, immediate operational value\n",
    "- **7-8:** Good - Useful information with some technical specifics\n",
    "- **5-6:** Moderate - Some value but limited technical depth\n",
    "- **3-4:** Limited - Minimal actionable intelligence\n",
    "- **1-2:** Poor - Mostly strategic/general information with little operational value\n",
    "\n",
    "**Output Format:**\n",
    "**HUNTABILITY SCORE: [1-10]**\n",
    "\n",
    "**KEY FINDINGS:**\n",
    "[List the most important technical details, commands, or indicators]\n",
    "\n",
    "**ACTIONABLE INTELLIGENCE:**\n",
    "[Specific steps security teams can take]\n",
    "\n",
    "**DETECTION OPPORTUNITIES:**\n",
    "[What can be monitored or detected]\n",
    "\n",
    "**THREAT HUNTING VALUE:**\n",
    "[How this supports proactive hunting activities]\n",
    "\n",
    "**OPERATIONAL RECOMMENDATIONS:**\n",
    "[Specific actions for security teams]\n",
    "\n",
    "Please analyze the following content:\n",
    "\n",
    "{content}\"\"\"\n",
    "\n",
    "print(\"üìù Current Ranking Prompt:\")\n",
    "print(RANKING_PROMPT[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: LLM Rank Article\n",
    "async def test_rank_article(\n",
    "    title: str,\n",
    "    content: str,\n",
    "    source: str,\n",
    "    url: str,\n",
    "    prompt_template: str = None\n",
    "):\n",
    "    \"\"\"Test ranking step with custom prompt.\"\"\"\n",
    "    print(\"üìä Running LLM Ranking...\")\n",
    "    \n",
    "    # Use custom prompt if provided, otherwise use default\n",
    "    if prompt_template:\n",
    "        # Save to temp file for LLM service\n",
    "        import tempfile\n",
    "        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:\n",
    "            f.write(prompt_template)\n",
    "            temp_path = f.name\n",
    "        \n",
    "        ranking_result = await llm_service.rank_article(\n",
    "            title=title,\n",
    "            content=content,\n",
    "            source=source,\n",
    "            url=url,\n",
    "            prompt_template_path=temp_path\n",
    "        )\n",
    "        \n",
    "        # Clean up temp file\n",
    "        os.unlink(temp_path)\n",
    "    else:\n",
    "        ranking_result = await llm_service.rank_article(\n",
    "            title=title,\n",
    "            content=content,\n",
    "            source=source,\n",
    "            url=url\n",
    "        )\n",
    "    \n",
    "    score = ranking_result['score']\n",
    "    reasoning = ranking_result.get('reasoning', 'No reasoning provided')\n",
    "    should_continue = score >= RANKING_THRESHOLD\n",
    "    \n",
    "    print(f\"‚úÖ Ranking Result:\")\n",
    "    print(f\"   Score: {score:.1f}/10\")\n",
    "    print(f\"   Threshold: {RANKING_THRESHOLD}/10\")\n",
    "    print(f\"   Should Continue: {should_continue}\")\n",
    "    print(f\"\\n   Reasoning:\\n{reasoning}\")\n",
    "    \n",
    "    return {\n",
    "        'score': score,\n",
    "        'reasoning': reasoning,\n",
    "        'should_continue': should_continue\n",
    "    }\n",
    "\n",
    "# Run ranking\n",
    "ranking_result = await test_rank_article(\n",
    "    title=article['title'],\n",
    "    content=filtered_content,\n",
    "    source=article['source_name'],\n",
    "    url=article['url'],\n",
    "    prompt_template=RANKING_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract Agent\n",
    "\n",
    "Extracts behavioral observables and IOCs. **Edit the prompts below** to customize extraction behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editable ExtractAgent Prompt (JSON config)\n",
    "EXTRACT_AGENT_CONFIG = {\n",
    "    \"role\": \"You are a detection engineer LLM. Your task is to extract telemetry-aware attacker techniques and observables that are useful to detection engineers and threat hunters.\",\n",
    "    \"objective\": \"Extract telemetry-based observables (command-line executions, process chains, service/registry modifications, file path usage, event log manipulation). Output unique and discrete entries only.\",\n",
    "    \"exclusions\": {\n",
    "        \"do_not_extract\": [\n",
    "            \"Atomic IOCs like single IP addresses, domains, or file hashes\",\n",
    "            \"One-off URLs or email addresses without recognizable structure or patterns\"\n",
    "        ],\n",
    "        \"do_extract\": [\n",
    "            \"Command-line executions (especially chained or obfuscated)\",\n",
    "            \"Parent ‚Üí child process chains\",\n",
    "            \"Registry key/value modification patterns\",\n",
    "            \"Service manipulation (creation, deletion, status change)\",\n",
    "            \"Suspicious file paths or locations (Temp dirs, uncommon drive paths)\",\n",
    "            \"Event log deletion or manipulation\",\n",
    "            \"Encoded or obfuscated values\"\n",
    "        ]\n",
    "    },\n",
    "    \"output_format\": {\n",
    "        \"behavioral_observables\": \"Array of unique observables with tags (e.g., process_cmdline, registry_pattern, service_command)\",\n",
    "        \"observable_list\": \"Array of raw observable strings (deduplicated, plaintext)\",\n",
    "        \"detection_queries\": \"Optional array of KQL/Sigma-like query fragments, if evident\",\n",
    "        \"url\": \"Source URL of the original content\",\n",
    "        \"content\": \"Concise extracted raw text that includes only the observables (e.g., attacker commands, registry paths, etc.)\",\n",
    "        \"discrete_huntables_count\": \"Integer value representing the number of unique discrete observables extracted\"\n",
    "    },\n",
    "    \"platform_coverage\": {\n",
    "        \"valid_sources\": [\n",
    "            \"Windows: Sysmon, Security Logs\",\n",
    "            \"Linux: auditd, Syslog\",\n",
    "            \"macOS: EndpointSecurity, Unified Logs\",\n",
    "            \"Cloud: AWS CloudTrail, Azure Activity Logs, GCP Audit Logs\"\n",
    "        ]\n",
    "    },\n",
    "    \"instructions\": \"Read the threat report. Extract **only** telemetry-relevant attacker behaviors and observables that can be captured by EDR/logs. All observables must be unique. Remove any duplicates. Use exact strings or <placeholder> where appropriate. Output must be a **valid JSON object only** (no markdown, no explanations).\"\n",
    "}\n",
    "\n",
    "# Editable ExtractAgent Instructions Template\n",
    "EXTRACT_AGENT_INSTRUCTIONS = \"\"\"Title: {title}\n",
    "\n",
    "URL: {url}\n",
    "\n",
    "Content:\n",
    "\n",
    "{content}\n",
    "\n",
    "Extract telemetry-aware attacker behaviors and observables.\n",
    "\n",
    "{prompt_config}\n",
    "\n",
    "CRITICAL: Output your response as a valid JSON object only. Begin with {{{{ and end with }}}}. Do not include reasoning, explanations, or markdown outside the JSON object.\"\"\"\n",
    "\n",
    "print(\"üìù ExtractAgent Config:\")\n",
    "print(json.dumps(EXTRACT_AGENT_CONFIG, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Extract Agent\n",
    "async def test_extract_agent(\n",
    "    title: str,\n",
    "    content: str,\n",
    "    url: str,\n",
    "    extract_config: dict = None,\n",
    "    instructions_template: str = None\n",
    "):\n",
    "    \"\"\"Test extraction step with custom prompts.\"\"\"\n",
    "    print(\"üî¨ Running Extract Agent...\")\n",
    "    \n",
    "    # Create temp prompt files\n",
    "    import tempfile\n",
    "    \n",
    "    # Save config to temp file\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='_ExtractAgent', delete=False) as f:\n",
    "        json.dump(extract_config or EXTRACT_AGENT_CONFIG, f, indent=2)\n",
    "        config_path = f.name\n",
    "    \n",
    "    # Save instructions template\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='_ExtractAgentInstructions.txt', delete=False) as f:\n",
    "        f.write(instructions_template or EXTRACT_AGENT_INSTRUCTIONS)\n",
    "        instructions_path = f.name\n",
    "    \n",
    "    try:\n",
    "        extraction_result = await llm_service.extract_behaviors(\n",
    "            content=content,\n",
    "            title=title,\n",
    "            url=url,\n",
    "            prompt_file_path=config_path\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Extraction Result:\")\n",
    "        print(f\"   Discrete Huntables: {extraction_result.get('discrete_huntables_count', 0)}\")\n",
    "        \n",
    "        # Display observable_list (like curl command output)\n",
    "        observable_list = extraction_result.get('observable_list', [])\n",
    "        if observable_list:\n",
    "            print(f\"\\n   üìã Observable List ({len(observable_list)} items):\")\n",
    "            for i, obs in enumerate(observable_list[:50], 1):  # Show first 50\n",
    "                print(f\"      {i:2d}. {obs}\")\n",
    "            if len(observable_list) > 50:\n",
    "                print(f\"      ... and {len(observable_list) - 50} more\")\n",
    "        \n",
    "        # Display behavioral observables\n",
    "        behavioral_obs = extraction_result.get('behavioral_observables', [])\n",
    "        if behavioral_obs:\n",
    "            print(f\"\\n   üéØ Behavioral Observables ({len(behavioral_obs)} items):\")\n",
    "            for i, obs in enumerate(behavioral_obs[:20], 1):  # Show first 20\n",
    "                print(f\"      {i:2d}. {obs}\")\n",
    "            if len(behavioral_obs) > 20:\n",
    "                print(f\"      ... and {len(behavioral_obs) - 20} more\")\n",
    "        \n",
    "        # Display detection queries\n",
    "        detection_queries = extraction_result.get('detection_queries', [])\n",
    "        if detection_queries:\n",
    "            print(f\"\\n   üîç Detection Queries ({len(detection_queries)} items):\")\n",
    "            for i, query in enumerate(detection_queries[:10], 1):  # Show first 10\n",
    "                print(f\"      {i:2d}. {query}\")\n",
    "            if len(detection_queries) > 10:\n",
    "                print(f\"      ... and {len(detection_queries) - 10} more\")\n",
    "        \n",
    "        return extraction_result\n",
    "        \n",
    "    finally:\n",
    "        # Clean up temp files\n",
    "        os.unlink(config_path)\n",
    "        os.unlink(instructions_path)\n",
    "\n",
    "# Run extraction\n",
    "extraction_result = await test_extract_agent(\n",
    "    title=article['title'],\n",
    "    content=filtered_content,\n",
    "    url=article['url'],\n",
    "    extract_config=EXTRACT_AGENT_CONFIG,\n",
    "    instructions_template=EXTRACT_AGENT_INSTRUCTIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate SIGMA Rules\n",
    "\n",
    "Generates SIGMA detection rules. **Edit the prompt below** to customize SIGMA generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editable SIGMA Generation Prompt\n",
    "SIGMA_GENERATION_PROMPT = \"\"\"Generate a SIGMA detection rule in valid YAML format.\n",
    "\n",
    "Article: {title}\n",
    "Source: {source}\n",
    "\n",
    "Content:\n",
    "{content}\n",
    "\n",
    "CRITICAL: Output ONLY valid YAML. No explanatory text. No markdown blocks.\n",
    "\n",
    "Example format (copy this structure exactly):\n",
    "\n",
    "title: Suspicious PowerShell Execution\n",
    "id: 12345678-1234-1234-1234-123456789abc\n",
    "description: Detects suspicious PowerShell commands\n",
    "logsource:\n",
    "  category: process_creation\n",
    "  product: windows\n",
    "detection:\n",
    "  selection:\n",
    "    Image|endswith: '\\\\powershell.exe'\n",
    "    CommandLine|contains: 'bypass'\n",
    "  condition: selection\n",
    "level: high\n",
    "status: experimental\n",
    "tags:\n",
    "  - attack.execution\n",
    "  - attack.t1059.001\n",
    "references:\n",
    "  - {url}\n",
    "\n",
    "IMPORTANT FORMATTING RULES:\n",
    "1. logsource MUST be indented with 2 spaces under the key\n",
    "2. detection MUST be indented with 2 spaces under the key\n",
    "3. tags MUST be a list with \"- \" prefix\n",
    "4. Use lowercase for all field names\n",
    "5. Start output with \"title:\" - no text before it\"\"\"\n",
    "\n",
    "print(\"üìù SIGMA Generation Prompt:\")\n",
    "print(SIGMA_GENERATION_PROMPT[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate SIGMA Rules\n",
    "async def test_generate_sigma(\n",
    "    title: str,\n",
    "    content: str,\n",
    "    source: str,\n",
    "    url: str,\n",
    "    custom_prompt: str = None\n",
    "):\n",
    "    \"\"\"Test SIGMA generation with custom prompt.\"\"\"\n",
    "    print(\"‚ö° Running SIGMA Generation...\")\n",
    "    \n",
    "    # Note: SigmaGenerationService uses prompt_loader which loads from src/prompts/\n",
    "    # For custom prompts, we'd need to modify the service or temporarily replace the prompt file\n",
    "    \n",
    "    generation_result = await sigma_service.generate_sigma_rules(\n",
    "        article_title=title,\n",
    "        article_content=content,\n",
    "        source_name=source,\n",
    "        url=url,\n",
    "        ai_model=SIGMA_MODEL,\n",
    "        max_attempts=3,\n",
    "        min_confidence=0.9\n",
    "    )\n",
    "    \n",
    "    rules = generation_result.get('rules', [])\n",
    "    errors = generation_result.get('errors', [])\n",
    "    \n",
    "    print(f\"‚úÖ SIGMA Generation Result:\")\n",
    "    print(f\"   Rules Generated: {len(rules)}\")\n",
    "    \n",
    "    if rules:\n",
    "        print(f\"\\n   üìã SIGMA Rules:\")\n",
    "        for i, rule in enumerate(rules[:5], 1):  # Show first 5\n",
    "            rule_title = rule.get('title', 'Untitled')\n",
    "            rule_id = rule.get('id', 'No ID')\n",
    "            print(f\"      {i}. {rule_title} (ID: {rule_id})\")\n",
    "        if len(rules) > 5:\n",
    "            print(f\"      ... and {len(rules) - 5} more\")\n",
    "    \n",
    "    if errors:\n",
    "        print(f\"\\n   ‚ö†Ô∏è  Errors:\")\n",
    "        for error in errors[:3]:\n",
    "            print(f\"      - {error}\")\n",
    "    \n",
    "    return generation_result\n",
    "\n",
    "# Run SIGMA generation\n",
    "sigma_result = await test_generate_sigma(\n",
    "    title=article['title'],\n",
    "    content=filtered_content,\n",
    "    source=article['source_name'],\n",
    "    url=article['url']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Similarity Search\n",
    "\n",
    "Searches for similar existing SIGMA rules in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Similarity Search\n",
    "async def test_similarity_search(\n",
    "    sigma_rules: list,\n",
    "    max_results: int = 10\n",
    "):\n",
    "    \"\"\"Test similarity search for generated SIGMA rules.\"\"\"\n",
    "    print(\"üîé Running Similarity Search...\")\n",
    "    \n",
    "    if not sigma_rules:\n",
    "        print(\"‚ö†Ô∏è  No SIGMA rules to search\")\n",
    "        return []\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for rule in sigma_rules:\n",
    "        rule_title = rule.get('title', 'Untitled')\n",
    "        rule_description = rule.get('description', '')\n",
    "        \n",
    "        # Create query from rule title and description\n",
    "        query = f\"{rule_title} {rule_description}\".strip()\n",
    "        \n",
    "        # Search for similar rules\n",
    "        try:\n",
    "            search_results = await rag_service.search_similar_sigma_rules(\n",
    "                query=query,\n",
    "                limit=max_results\n",
    "            )\n",
    "            \n",
    "            all_results.append({\n",
    "                'rule_title': rule_title,\n",
    "                'similar_rules': search_results\n",
    "            })\n",
    "            \n",
    "            print(f\"\\n   Rule: {rule_title}\")\n",
    "            print(f\"   Similar rules found: {len(search_results)}\")\n",
    "            \n",
    "            if search_results:\n",
    "                max_sim = max((r.get('similarity', 0) for r in search_results), default=0)\n",
    "                print(f\"   Max similarity: {max_sim:.3f}\")\n",
    "                \n",
    "                # Show top 3 results\n",
    "                for i, result in enumerate(search_results[:3], 1):\n",
    "                    sim = result.get('similarity', 0)\n",
    "                    title = result.get('title', 'Unknown')\n",
    "                    print(f\"      {i}. {title} (similarity: {sim:.3f})\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Error searching for '{rule_title}': {e}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Run similarity search\n",
    "sigma_rules = sigma_result.get('rules', []) if 'sigma_result' in locals() else []\n",
    "similarity_results = await test_similarity_search(sigma_rules, max_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Promote to Queue\n",
    "\n",
    "Promotes rules to queue if similarity is low (rules are unique enough)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Promote to Queue\n",
    "def test_promote_to_queue(\n",
    "    sigma_rules: list,\n",
    "    similarity_results: list,\n",
    "    max_similarity_threshold: float = 0.7\n",
    "):\n",
    "    \"\"\"Test queue promotion logic.\"\"\"\n",
    "    print(\"üì§ Running Queue Promotion Logic...\")\n",
    "    \n",
    "    if not sigma_rules:\n",
    "        print(\"‚ö†Ô∏è  No SIGMA rules to promote\")\n",
    "        return []\n",
    "    \n",
    "    queued_rules = []\n",
    "    \n",
    "    for i, rule in enumerate(sigma_rules):\n",
    "        rule_title = rule.get('title', 'Untitled')\n",
    "        \n",
    "        # Get similarity results for this rule\n",
    "        similarity_info = similarity_results[i] if i < len(similarity_results) else None\n",
    "        \n",
    "        if similarity_info and similarity_info.get('similar_rules'):\n",
    "            max_sim = max((r.get('similarity', 0) for r in similarity_info['similar_rules']), default=0)\n",
    "        else:\n",
    "            max_sim = 0.0\n",
    "        \n",
    "        # Promote if similarity is below threshold\n",
    "        if max_sim < max_similarity_threshold:\n",
    "            queued_rules.append({\n",
    "                'rule': rule,\n",
    "                'max_similarity': max_sim,\n",
    "                'reason': 'Low similarity to existing rules'\n",
    "            })\n",
    "            print(f\"   ‚úÖ Queued: {rule_title} (max similarity: {max_sim:.3f})\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Skipped: {rule_title} (max similarity: {max_sim:.3f} >= {max_similarity_threshold})\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Total rules queued: {len(queued_rules)}/{len(sigma_rules)}\")\n",
    "    \n",
    "    return queued_rules\n",
    "\n",
    "# Run queue promotion\n",
    "queued_rules = test_promote_to_queue(\n",
    "    sigma_rules,\n",
    "    similarity_results,\n",
    "    max_similarity_threshold=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Complete Workflow Results\n",
    "\n",
    "Display comprehensive results similar to `trigger_workflow.py` output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comprehensive results (similar to trigger_workflow.py)\n",
    "def display_workflow_results(\n",
    "    article: dict,\n",
    "    junk_filter_result: dict,\n",
    "    ranking_result: dict,\n",
    "    extraction_result: dict,\n",
    "    sigma_result: dict,\n",
    "    similarity_results: list,\n",
    "    queued_rules: list\n",
    "):\n",
    "    \"\"\"Display complete workflow results.\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üìä COMPLETE WORKFLOW RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Article info\n",
    "    print(f\"\\nüì∞ Article:\")\n",
    "    print(f\"   ID: {article['id']}\")\n",
    "    print(f\"   Title: {article['title']}\")\n",
    "    print(f\"   Source: {article['source_name']}\")\n",
    "    \n",
    "    # Junk Filter\n",
    "    print(f\"\\nüîç Junk Filter:\")\n",
    "    print(f\"   Filtered: {junk_filter_result['filtered']}\")\n",
    "    print(f\"   Confidence: {junk_filter_result['confidence']:.3f}\")\n",
    "    print(f\"   Length: {junk_filter_result['original_length']:,} ‚Üí {junk_filter_result['filtered_length']:,} chars\")\n",
    "    \n",
    "    # Ranking\n",
    "    print(f\"\\nüìà Ranking:\")\n",
    "    print(f\"   Score: {ranking_result['score']:.1f}/10\")\n",
    "    print(f\"   Should Continue: {ranking_result['should_continue']}\")\n",
    "    \n",
    "    # Extraction\n",
    "    print(f\"\\nüî¨ Extraction:\")\n",
    "    print(f\"   Discrete Huntables: {extraction_result.get('discrete_huntables_count', 0)}\")\n",
    "    \n",
    "    observable_list = extraction_result.get('observable_list', [])\n",
    "    if observable_list:\n",
    "        print(f\"\\n   üìã Observable List ({len(observable_list)} items):\")\n",
    "        for i, obs in enumerate(observable_list[:100], 1):  # Show first 100\n",
    "            print(f\"      {i:3d}. {obs}\")\n",
    "        if len(observable_list) > 100:\n",
    "            print(f\"      ... and {len(observable_list) - 100} more\")\n",
    "    \n",
    "    behavioral_obs = extraction_result.get('behavioral_observables', [])\n",
    "    if behavioral_obs:\n",
    "        print(f\"\\n   üéØ Behavioral Observables ({len(behavioral_obs)} items):\")\n",
    "        for i, obs in enumerate(behavioral_obs[:50], 1):  # Show first 50\n",
    "            print(f\"      {i:2d}. {obs}\")\n",
    "        if len(behavioral_obs) > 50:\n",
    "            print(f\"      ... and {len(behavioral_obs) - 50} more\")\n",
    "    \n",
    "    # SIGMA Rules\n",
    "    sigma_rules = sigma_result.get('rules', [])\n",
    "    print(f\"\\n‚ö° SIGMA Rules Generated: {len(sigma_rules)}\")\n",
    "    for i, rule in enumerate(sigma_rules[:5], 1):\n",
    "        title = rule.get('title', 'Untitled')\n",
    "        print(f\"   {i}. {title}\")\n",
    "    if len(sigma_rules) > 5:\n",
    "        print(f\"   ... and {len(sigma_rules) - 5} more\")\n",
    "    \n",
    "    # Similarity Search\n",
    "    if similarity_results:\n",
    "        print(f\"\\nüîé Similarity Search:\")\n",
    "        total_similar = sum(len(r.get('similar_rules', [])) for r in similarity_results)\n",
    "        print(f\"   Total Similar Rules Found: {total_similar}\")\n",
    "        if similarity_results:\n",
    "            max_sims = []\n",
    "            for result in similarity_results:\n",
    "                similar_rules = result.get('similar_rules', [])\n",
    "                if similar_rules:\n",
    "                    max_sims.append(max((r.get('similarity', 0) for r in similar_rules), default=0))\n",
    "            if max_sims:\n",
    "                print(f\"   Max Similarity: {max(max_sims):.3f}\")\n",
    "    \n",
    "    # Queue Promotion\n",
    "    print(f\"\\nüì§ Queue Promotion:\")\n",
    "    print(f\"   Rules Queued: {len(queued_rules)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Display results\n",
    "if 'junk_filter_result' in locals() and 'ranking_result' in locals() and 'extraction_result' in locals():\n",
    "    display_workflow_results(\n",
    "        article,\n",
    "        junk_filter_result,\n",
    "        ranking_result,\n",
    "        extraction_result,\n",
    "        sigma_result if 'sigma_result' in locals() else {'rules': []},\n",
    "        similarity_results if 'similarity_results' in locals() else [],\n",
    "        queued_rules if 'queued_rules' in locals() else []\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "\n",
    "Export results to JSON for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to JSON\n",
    "def export_results(\n",
    "    article: dict,\n",
    "    junk_filter_result: dict,\n",
    "    ranking_result: dict,\n",
    "    extraction_result: dict,\n",
    "    sigma_result: dict,\n",
    "    similarity_results: list,\n",
    "    queued_rules: list,\n",
    "    filename: str = None\n",
    "):\n",
    "    \"\"\"Export workflow results to JSON file.\"\"\"\n",
    "    \n",
    "    results = {\n",
    "        'article_id': article['id'],\n",
    "        'article_title': article['title'],\n",
    "        'timestamp': datetime.utcnow().isoformat(),\n",
    "        'junk_filter_result': junk_filter_result,\n",
    "        'ranking_result': ranking_result,\n",
    "        'extraction_result': extraction_result,\n",
    "        'sigma_result': sigma_result,\n",
    "        'similarity_results': similarity_results,\n",
    "        'queued_rules': queued_rules\n",
    "    }\n",
    "    \n",
    "    if filename is None:\n",
    "        filename = f\"workflow_results_{article['id']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"‚úÖ Results exported to: {filename}\")\n",
    "    return filename\n",
    "\n",
    "# Export if all results are available\n",
    "if all(var in locals() for var in ['junk_filter_result', 'ranking_result', 'extraction_result']):\n",
    "    export_filename = export_results(\n",
    "        article,\n",
    "        junk_filter_result,\n",
    "        ranking_result,\n",
    "        extraction_result,\n",
    "        sigma_result if 'sigma_result' in locals() else {'rules': [], 'errors': []},\n",
    "        similarity_results if 'similarity_results' in locals() else [],\n",
    "        queued_rules if 'queued_rules' in locals() else []\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
