{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ CTI-to-Hunt Logic Fine-Tuning (MacBook Local)\n",
    "\n",
    "**Goal**: Fine-tune Mistral 7B locally on Apple Silicon to convert CTI text into hunt logic.\n",
    "\n",
    "**Hardware**: MacBook with MPS (Metal Performance Shaders)\n",
    "**Model**: Mistral 7B Instruct (optimal for MacBook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 1: Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.5 (v3.11.5:cce6ba91b3, Aug 24 2023, 10:50:31) [Clang 13.0.0 (clang-1300.0.29.30)]\n",
      "PyTorch version: 2.8.0\n",
      "MPS available: True\n",
      "MPS built: True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"MPS built: {torch.backends.mps.is_built()}\")\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 2: Load Phi-3-mini-4k-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading microsoft/Phi-3-mini-4k-instruct (no auth required)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33a1815bdee4cddab996d797b25c337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Parameters: 3,821,079,552\n",
      "Device: mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "print(f\"Loading {model_name} (no auth required)...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    model = model.to(\"mps\")\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Step 3: Test Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Base Model Output:\n",
      "==================================================\n",
      "To create a hunt logic for detecting the mentioned malware behavior, we need to define the indicators of compromise (IoCs) and the logic to search for them. Here's an example of hunt logic that could be used to detect the malware's persistence mechanism:\n",
      "\n",
      "```powershell\n",
      "# Define the search parameters\n",
      "$serviceName = \"WindowsUpdateService\"\n",
      "$payloadPath = \"C:\\Windows\\Temp\\update.exe\"\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "test_prompt = \"[INST] Convert this cyber threat intelligence into concise hunt logic: The malware establishes persistence by creating a new Windows service named WindowsUpdateService that executes a payload from C:\\\\Windows\\\\Temp\\\\update.exe. Hunt Logic: [/INST]\"\n",
    "\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\")\n",
    "if torch.backends.mps.is_available():\n",
    "    inputs = {k: v.to(\"mps\") for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "hunt_logic = response.split(\"[/INST]\")[-1].strip()\n",
    "\n",
    "print(\"üéØ Base Model Output:\")\n",
    "print(\"=\" * 50)\n",
    "print(hunt_logic)\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Step 4: Training Data"
   ]
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\nfrom pathlib import Path\n\n# Load your CSV training data\ncsv_file_path = input(\"Enter path to your CSV file (or drag and drop): \").strip()\n\n# Remove quotes if drag-and-drop added them\ncsv_file_path = csv_file_path.strip('\"').strip(\"'\")\n\nif Path(csv_file_path).exists():\n    print(f\"Loading training data from: {csv_file_path}\")\n    \n    # Load CSV\n    df = pd.read_csv(csv_file_path)\n    print(f\"‚úÖ Loaded {len(df)} rows\")\n    print(f\"üìä Columns: {list(df.columns)}\")\n    \n    # Show first few rows to understand format\n    print(\"\\nüîç Sample data:\")\n    print(df.head(3))\n    \n    # Ask user to identify the columns\n    print(f\"\\nüìù Please identify your columns:\")\n    input_column = input(\"Which column contains the CTI text? \").strip()\n    output_column = input(\"Which column contains the hunt logic? (leave empty if none): \").strip()\n    \n    if input_column in df.columns:\n        cti_texts = df[input_column].dropna().tolist()\n        \n        if output_column and output_column in df.columns:\n            hunt_logics = df[output_column].dropna().tolist()\n            print(f\"‚úÖ Found {len(cti_texts)} CTI texts and {len(hunt_logics)} hunt logics\")\n            \n            # Create training pairs\n            training_data = []\n            for i, (cti, hunt) in enumerate(zip(cti_texts, hunt_logics)):\n                if pd.notna(cti) and pd.notna(hunt):\n                    training_data.append({\n                        \"input\": f\"<|user|>Convert this threat intelligence into concise hunt logic: {cti}<|end|><|assistant|>\",\n                        \"output\": str(hunt)\n                    })\n            \n            print(f\"üéØ Created {len(training_data)} training examples\")\n            \n        else:\n            print(f\"‚úÖ Found {len(cti_texts)} CTI texts (no hunt logic column)\")\n            print(\"üí° You can manually add hunt logic or use the model to generate examples\")\n            \n            # Show some examples for manual labeling\n            print(\"\\nüìã First 3 examples for manual review:\")\n            for i, text in enumerate(cti_texts[:3]):\n                print(f\"\\n{i+1}. CTI: {text[:200]}...\")\n                \n    else:\n        print(f\"‚ùå Column '{input_column}' not found in CSV\")\n        \nelse:\n    print(f\"‚ùå File not found: {csv_file_path}\")\n    print(\"üí° Make sure the path is correct or drag and drop the file\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import ipywidgets as widgets\nfrom IPython.display import display, clear_output\n\ndef create_hunt_logic_interface():\n    # Create input widget\n    input_text = widgets.Textarea(\n        value='',\n        placeholder='Paste your CTI text here (e.g., \"The malware creates a service...\")',\n        description='CTI Input:',\n        layout=widgets.Layout(width='100%', height='150px')\n    )\n    \n    # Create output widget\n    output_area = widgets.Output()\n    \n    # Create button\n    generate_button = widgets.Button(\n        description='üéØ Generate Hunt Logic',\n        button_style='primary',\n        layout=widgets.Layout(width='200px')\n    )\n    \n    # Create clear button\n    clear_button = widgets.Button(\n        description='üóëÔ∏è Clear',\n        button_style='warning',\n        layout=widgets.Layout(width='100px')\n    )\n    \n    def on_generate_click(b):\n        with output_area:\n            clear_output()\n            \n            cti_input = input_text.value.strip()\n            if not cti_input:\n                print(\"‚ùå Please enter some CTI text first!\")\n                return\n                \n            print(\"üîÑ Generating hunt logic...\")\n            print(f\"üìù Input: {cti_input[:100]}{'...' if len(cti_input) > 100 else ''}\")\n            print(\"\\n\" + \"=\"*50)\n            \n            try:\n                # Format prompt for Phi-3\n                prompt = f\"<|user|>Convert this cyber threat intelligence into concise hunt logic:\\n\\n{cti_input}\\n\\nHunt Logic:<|end|><|assistant|>\"\n                \n                # Tokenize and generate\n                inputs = tokenizer(prompt, return_tensors=\"pt\")\n                if torch.backends.mps.is_available():\n                    inputs = {k: v.to(\"mps\") for k, v in inputs.items()}\n                \n                with torch.no_grad():\n                    outputs = model.generate(\n                        **inputs,\n                        max_new_tokens=150,\n                        temperature=0.3,\n                        do_sample=True,\n                        pad_token_id=tokenizer.eos_token_id,\n                        eos_token_id=tokenizer.eos_token_id\n                    )\n                \n                # Decode response\n                full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n                hunt_logic = full_response.split(\"<|assistant|>\")[-1].strip()\n                \n                print(\"üéØ HUNT LOGIC GENERATED:\")\n                print(\"-\" * 30)\n                print(hunt_logic)\n                print(\"-\" * 30)\n                print(f\"‚úÖ Generated {len(hunt_logic)} characters\")\n                \n            except Exception as e:\n                print(f\"‚ùå Error generating hunt logic: {str(e)}\")\n    \n    def on_clear_click(b):\n        input_text.value = ''\n        with output_area:\n            clear_output()\n    \n    # Bind functions to buttons\n    generate_button.on_click(on_generate_click)\n    clear_button.on_click(on_clear_click)\n    \n    # Create layout\n    buttons = widgets.HBox([generate_button, clear_button])\n    interface = widgets.VBox([\n        widgets.HTML(\"<h3>üéØ CTI-to-Hunt Logic Generator</h3>\"),\n        input_text,\n        buttons,\n        output_area\n    ])\n    \n    return interface\n\n# Create and display the interface\nprint(\"üöÄ Creating interactive CTI-to-Hunt Logic interface...\")\ninterface = create_hunt_logic_interface()\ndisplay(interface)\nprint(\"‚úÖ Interface ready! Paste CTI text above and click 'Generate Hunt Logic'\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Training examples ready: 2\n"
     ]
    }
   ],
   "source": [
    "training_examples = [\n",
    "    {\n",
    "        \"input\": \"[INST] Convert this threat intelligence into concise hunt logic: The malware creates a scheduled task named SystemUpdate that runs C:\\\\Users\\\\Public\\\\svchost.exe every 5 minutes with SYSTEM privileges. Hunt Logic: [/INST]\",\n",
    "        \"output\": \"Scheduled Task Creation: Name=SystemUpdate\\nProcess Execution: C:\\\\Users\\\\Public\\\\svchost.exe\\nPrivilege Escalation: SYSTEM context\\nPersistence: Auto-start\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"[INST] Convert this threat intelligence into concise hunt logic: Network traffic shows malware communicating with 192.168.1.100:8080 via HTTP POST with Mozilla User-Agent and base64 encoded data. Hunt Logic: [/INST]\",\n",
    "        \"output\": \"Network Connection: 192.168.1.100:8080\\nProtocol: HTTP POST\\nUser-Agent: Mozilla/5.0\\nData Encoding: Base64\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üìä Training examples ready: {len(training_examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 5: Setup Complete\n",
    "\n",
    "Your MacBook fine-tuning environment is ready!\n",
    "- Mistral 7B loaded with MPS acceleration\n",
    "- Training data in Mistral format\n",
    "- Ready for LoRA fine-tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}