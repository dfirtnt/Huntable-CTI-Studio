services:
  # PostgreSQL Database with pgvector extension
  postgres:
    image: pgvector/pgvector:pg15
    container_name: cti_postgres
    environment:
      POSTGRES_DB: cti_scraper
      POSTGRES_USER: cti_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    networks:
      - cti_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U cti_user -d cti_scraper"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis for caching and background tasks
  redis:
    image: redis:7-alpine
    container_name: cti_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - cti_network
    restart: unless-stopped
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD-SHELL", "timeout 3 redis-cli ping | grep -q PONG"]
      interval: 30s
      timeout: 10s
      retries: 3

  # FastAPI Web Application
  web:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: cti_web
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - DATABASE_URL=postgresql+asyncpg://cti_user:${POSTGRES_PASSWORD}@postgres:5432/cti_scraper
      - REDIS_URL=redis://redis:6379/0
      - ENVIRONMENT=development
      - LOG_LEVEL=DEBUG
      - LLM_MODEL=tinyllama
      - LLM_TEMPERATURE=0.3
      - LLM_MAX_TOKENS=2048
      - CHATGPT_CONTENT_LIMIT=1000000
      - USE_LLM_RESPONSES=true
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_URL=https://api.anthropic.com/v1/messages
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - ANTHROPIC_CONTENT_LIMIT=1000000
      - CHATGPT_API_KEY=${CHATGPT_API_KEY}
      - LMSTUDIO_API_URL=${LMSTUDIO_API_URL:-http://host.docker.internal:1234/v1}
      - LMSTUDIO_MODEL=deepseek/deepseek-r1-0528-qwen3-8b
      - LMSTUDIO_MODEL_RANK=qwen/qwen3-4b-2507
      - LMSTUDIO_MODEL_EXTRACT=${LMSTUDIO_MODEL_EXTRACT:-qwen/qwen3-4b-2507}
      - LMSTUDIO_MODEL_SIGMA=${LMSTUDIO_MODEL_SIGMA:-qwen/qwen3-4b-2507}
      - LMSTUDIO_EMBEDDING_URL=${LMSTUDIO_EMBEDDING_URL:-http://host.docker.internal:1234/v1/embeddings}
      - LMSTUDIO_EMBEDDING_MODEL=${LMSTUDIO_EMBEDDING_MODEL:-text-embedding-e5-base-v2}
      # Context length overrides (LM Studio API doesn't report actual configured context)
      - LMSTUDIO_CONTEXT_LENGTH_gemma_3n_e4b_it_text=16384
      - LMSTUDIO_CONTEXT_LENGTH_deepseek_deepseek_r1_0528_qwen3_8b=16384
      - LMSTUDIO_CONTEXT_LENGTH_qwen_qwen3_4b_2507=16384
      - LANGSMITH_API_KEY=${LANGSMITH_API_KEY}
      # - LANGGRAPH_SERVER_URL=${LANGGRAPH_SERVER_URL:-http://langgraph-server:2024}
      - TZ=America/New_York
    ports:
      - "8001:8001"
      - "8888:8888"
    volumes:
      - ./src:/app/src
      - ./config:/app/config
      - ./logs:/app/logs
      - ./tests:/app/tests
      - ./backups:/app/backups
      - ./models:/app/models
      - ./outputs:/app/outputs
      - ./scripts:/app/scripts
      - ./allure-results:/app/allure-results
      - ./test-results:/app/test-results
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/db/timezone/zoneinfo/America/New_York:/etc/localtime:ro
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - cti_network
    restart: unless-stopped
    command: uvicorn src.web.modern_main:app --host 0.0.0.0 --port 8001 --reload

  # Celery Worker for Background Tasks
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: cti_worker
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - DATABASE_URL=postgresql+asyncpg://cti_user:${POSTGRES_PASSWORD}@postgres:5432/cti_scraper
      - REDIS_URL=redis://redis:6379/0
      - ENVIRONMENT=development
      - LOG_LEVEL=DEBUG
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - CHATGPT_API_KEY=${CHATGPT_API_KEY}
      - LMSTUDIO_API_URL=${LMSTUDIO_API_URL:-http://host.docker.internal:1234/v1}
      - LMSTUDIO_MODEL=deepseek/deepseek-r1-0528-qwen3-8b
      - LMSTUDIO_MODEL_RANK=qwen/qwen3-4b-2507
      - LMSTUDIO_MODEL_EXTRACT=${LMSTUDIO_MODEL_EXTRACT:-qwen/qwen3-4b-2507}
      - LMSTUDIO_MODEL_SIGMA=${LMSTUDIO_MODEL_SIGMA:-qwen/qwen3-4b-2507}
      - LMSTUDIO_EMBEDDING_URL=${LMSTUDIO_EMBEDDING_URL:-http://host.docker.internal:1234/v1/embeddings}
      - LMSTUDIO_EMBEDDING_MODEL=${LMSTUDIO_EMBEDDING_MODEL:-text-embedding-e5-base-v2}
      # Context length overrides (LM Studio API doesn't report actual configured context)
      - LMSTUDIO_CONTEXT_LENGTH_gemma_3n_e4b_it_text=16384
      - LMSTUDIO_CONTEXT_LENGTH_deepseek_deepseek_r1_0528_qwen3_8b=4096
      - LMSTUDIO_CONTEXT_LENGTH_qwen_qwen3_4b_2507=16384
    volumes:
      - ./src:/app/src
      - ./config:/app/config
      - ./logs:/app/logs
      - ./tests:/app/tests
      - ./outputs:/app/outputs
      - ./models:/app/models
      - ./scripts:/app/scripts
      - ./allure-results:/app/allure-results
      - ./test-results:/app/test-results
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - cti_network
    restart: unless-stopped
    command: celery -A src.worker.celery_app worker --loglevel=debug -Q default,source_checks,maintenance,reports,connectivity,collection
    healthcheck:
      test: ["CMD-SHELL", "celery -A src.worker.celery_app inspect ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Celery Worker for Workflow Tasks (Dedicated Queue)
  workflow_worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: cti_workflow_worker
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - DATABASE_URL=postgresql+asyncpg://cti_user:${POSTGRES_PASSWORD}@postgres:5432/cti_scraper
      - REDIS_URL=redis://redis:6379/0
      - ENVIRONMENT=development
      - LOG_LEVEL=DEBUG
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - CHATGPT_API_KEY=${CHATGPT_API_KEY}
      - LMSTUDIO_API_URL=${LMSTUDIO_API_URL:-http://host.docker.internal:1234/v1}
      - LMSTUDIO_MODEL=deepseek/deepseek-r1-0528-qwen3-8b
      - LMSTUDIO_MODEL_RANK=qwen/qwen3-4b-2507
      - LMSTUDIO_MODEL_EXTRACT=${LMSTUDIO_MODEL_EXTRACT:-qwen/qwen3-4b-2507}
      - LMSTUDIO_MODEL_SIGMA=${LMSTUDIO_MODEL_SIGMA:-qwen/qwen3-4b-2507}
      - LMSTUDIO_EMBEDDING_URL=${LMSTUDIO_EMBEDDING_URL:-http://host.docker.internal:1234/v1/embeddings}
      - LMSTUDIO_EMBEDDING_MODEL=${LMSTUDIO_EMBEDDING_MODEL:-text-embedding-e5-base-v2}
      # Context length overrides (LM Studio API doesn't report actual configured context)
      - LMSTUDIO_CONTEXT_LENGTH_gemma_3n_e4b_it_text=16384
      - LMSTUDIO_CONTEXT_LENGTH_deepseek_deepseek_r1_0528_qwen3_8b=4096
      - LMSTUDIO_CONTEXT_LENGTH_qwen_qwen3_4b_2507=16384
    volumes:
      - ./src:/app/src
      - ./config:/app/config
      - ./logs:/app/logs
      - ./tests:/app/tests
      - ./outputs:/app/outputs
      - ./models:/app/models
      - ./scripts:/app/scripts
      - ./allure-results:/app/allure-results
      - ./test-results:/app/test-results
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - cti_network
    restart: unless-stopped
    command: celery -A src.worker.celery_app worker --loglevel=debug -Q workflows --concurrency=4
    healthcheck:
      test: ["CMD-SHELL", "celery -A src.worker.celery_app inspect ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Celery Beat for Scheduled Tasks
  scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: cti_scheduler
    environment:
      - DATABASE_URL=postgresql+asyncpg://cti_user:${POSTGRES_PASSWORD}@postgres:5432/cti_scraper
      - REDIS_URL=redis://redis:6379/0
      - ENVIRONMENT=development
      - LOG_LEVEL=DEBUG
    volumes:
      - ./src:/app/src
      - ./config:/app/config
      - ./logs:/app/logs
      - ./tests:/app/tests
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - cti_network
    restart: unless-stopped
    command: celery -A src.worker.celery_app beat --loglevel=debug
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import sys; sys.exit(0)'"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s



  # CLI Tool Service
  cli:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: cti_cli
    environment:
      - DATABASE_URL=postgresql+asyncpg://cti_user:${POSTGRES_PASSWORD}@postgres:5432/cti_scraper
      - REDIS_URL=redis://redis:6379/0
      - ENVIRONMENT=development
      - LOG_LEVEL=DEBUG
      - SOURCES_CONFIG=/app/config/sources.yaml
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - CHATGPT_API_KEY=${CHATGPT_API_KEY}
    volumes:
      - ./src:/app/src
      - ./config:/app/config
      - ./logs:/app/logs
      - ./tests:/app/tests
      - ./data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - cti_network
    restart: unless-stopped
    profiles:
      - tools
    command: ["python", "-m", "src.cli.main"]

  # LangFlow for Visual LangChain/LangGraph Workflow Management
  # langflow:
    # image: langflowai/langflow:latest
    # container_name: cti_langflow
    # extra_hosts:
    #   - "host.docker.internal:host-gateway"
    # environment:
    #   - LANGFLOW_PORT=${LANGFLOW_PORT:-7860}
    #   - LANGFLOW_HOST=${LANGFLOW_HOST:-0.0.0.0}
    #   - LANGFLOW_DATABASE_URL=sqlite:///data/langflow.db
    #   - LANGGRAPH_SERVER_URL=http://langgraph-server:2024
    #   - OPENAI_API_KEY=${OPENAI_API_KEY}
    #   - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    #   - CHATGPT_API_KEY=${CHATGPT_API_KEY}
    #   - LMSTUDIO_API_URL=${LMSTUDIO_API_URL:-http://host.docker.internal:1234/v1}
    #   - LMSTUDIO_MODEL=${LMSTUDIO_MODEL:-deepseek/deepseek-r1-0528-qwen3-8b}
    #   - LMSTUDIO_API_KEY=dummy
    #   - LMSTUDIO_EMBEDDING_URL=${LMSTUDIO_EMBEDDING_URL:-http://host.docker.internal:1234/v1/embeddings}
    #   - LMSTUDIO_EMBEDDING_MODEL=${LMSTUDIO_EMBEDDING_MODEL:-text-embedding-e5-base-v2}
    #   - LANGSMITH_API_KEY=${LANGSMITH_API_KEY}
    #   - TZ=America/New_York
    # ports:
    #   - "${LANGFLOW_PORT:-7860}:7860"
    # volumes:
    #   - langflow_data:/data
    #   - ./langgraph.json:/app/langgraph.json:ro
    #   - ./langflow_components:/app/langflow_components:ro
    #   - ./src:/app/src:ro
    #   - ./config:/app/config:ro
    # depends_on:
    #   langgraph-server:
    #     condition: service_started
    # networks:
    #   - cti_network
    # restart: unless-stopped
    # healthcheck:
    #   test: ["CMD-SHELL", "curl -f http://localhost:7860/health || exit 1"]
    #   interval: 30s
    #   timeout: 10s
    #   retries: 3
    #   start_period: 60s

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  langflow_data:
    driver: local

networks:
  cti_network:
    driver: bridge
