{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SIGMA Generation Notebook\n",
        "Interact with the AI/ML modal's Generate SIGMA flow via the FastAPI endpoints.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import httpx\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "API_BASE = os.getenv(\"CTI_API_BASE\", \"http://localhost:8001/api\")\n",
        "ARTICLES_BASE = f\"{API_BASE}/articles\"\n",
        "DEFAULT_ARTICLE_ID = os.getenv(\"CTI_ARTICLE_ID\", \"68\")\n",
        "LMSTUDIO_BASE = os.getenv(\"LMSTUDIO_BASE\", \"http://localhost:1234/v1\")\n",
        "\n",
        "print(f'API base: {API_BASE}')\n",
        "print(f'Articles base: {ARTICLES_BASE}')\n",
        "print(f'Default article: {DEFAULT_ARTICLE_ID}')\n",
        "print(f'LMStudio base: {LMSTUDIO_BASE}')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def get_article(article_id: str):\n",
        "    url = f\"{ARTICLES_BASE}/{article_id}\"\n",
        "    try:\n",
        "        resp = httpx.get(url, timeout=10.0)\n",
        "        if resp.status_code == 200:\n",
        "            data = resp.json()\n",
        "            title = data.get('title', '')\n",
        "            print(f\"\u2705 Article {article_id}: {title[:80]}\")\n",
        "            return data\n",
        "        else:\n",
        "            print(f\"\u274c Article {article_id} fetch failed: {resp.status_code} {resp.text[:200]}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Error fetching article {article_id}: {e}\")\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def get_lmstudio_models():\n",
        "    try:\n",
        "        resp = httpx.get(f\"{LMSTUDIO_BASE}/models\", timeout=10.0)\n",
        "        if resp.status_code == 200:\n",
        "            data = resp.json()\n",
        "            models = [m['id'] for m in data.get('data', [])]\n",
        "            if models:\n",
        "                print(f\"\u2705 LMStudio models ({len(models)}): {models[:5]}{'...' if len(models)>5 else ''}\")\n",
        "            else:\n",
        "                print('\u26a0\ufe0f LMStudio returned no models')\n",
        "            return models\n",
        "        print(f\"\u274c LMStudio /models failed: {resp.status_code} {resp.text[:200]}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Error fetching LMStudio models: {e}\")\n",
        "    return []\n",
        "\n",
        "def set_lmstudio_model(model_id: str):\n",
        "    try:\n",
        "        resp = httpx.post(f\"{API_BASE}/settings\", json={'key': 'lmstudio_model', 'value': model_id}, timeout=10.0)\n",
        "        if resp.status_code == 200:\n",
        "            print(f\"\u2705 Set lmstudio_model to {model_id}\")\n",
        "            return True\n",
        "        print(f\"\u26a0\ufe0f Could not persist lmstudio_model (status {resp.status_code}): {resp.text[:200]}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0\ufe0f Error setting lmstudio_model: {e}\")\n",
        "    return False\n",
        "\n",
        "def generate_sigma(article_id, model_id, prompt_override, author='Notebook User', force=False, skip_matching=False):\n",
        "    # Ensure backend uses the selected LMStudio model\n",
        "    if model_id:\n",
        "        set_lmstudio_model(model_id)\n",
        "\n",
        "    url = f\"{ARTICLES_BASE}/{article_id}/generate-sigma\"\n",
        "    payload = {\n",
        "        'ai_model': 'lmstudio',\n",
        "        'author_name': author,\n",
        "        'force_regenerate': force,\n",
        "        'skip_matching': skip_matching,\n",
        "    }\n",
        "    if prompt_override:\n",
        "        payload['prompt_override'] = prompt_override\n",
        "\n",
        "    resp = httpx.post(url, json=payload, timeout=300.0)\n",
        "    try:\n",
        "        data = resp.json()\n",
        "    except Exception:\n",
        "        print(f\"\u274c Response not JSON (status {resp.status_code}): {resp.text[:400]}\")\n",
        "        return None\n",
        "\n",
        "    if resp.status_code == 200:\n",
        "        print(f\"\u2705 SIGMA API call succeeded (cached={data.get('cached')})\")\n",
        "    else:\n",
        "        print(f\"\u274c SIGMA API returned {resp.status_code}: {data}\")\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def summarize_rules(result):\n",
        "    if not result:\n",
        "        print('No result to summarize')\n",
        "        return None\n",
        "\n",
        "    rules = result.get('rules') or []\n",
        "    if not rules:\n",
        "        print('No rules returned.')\n",
        "        return None\n",
        "\n",
        "    rows = []\n",
        "    for idx, rule in enumerate(rules, 1):\n",
        "        rows.append({\n",
        "            'rule': idx,\n",
        "            'title': rule.get('title', '(untitled)'),\n",
        "            'validated': rule.get('validated', False),\n",
        "            'level': rule.get('level'),\n",
        "            'content_length': len(rule.get('content', '') or ''),\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    display(df)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive controls\n",
        "Run SIGMA generation, tweak the prompt, view validation status, and save results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Stateful results\n",
        "results_df = pd.DataFrame(columns=['timestamp', 'article_id', 'lmstudio_model', 'rules', 'valid_rules', 'cached', 'error'])\n",
        "last_response = {}\n",
        "\n",
        "# Load LMStudio models once at startup\n",
        "lmstudio_models = get_lmstudio_models()\n",
        "model_options = lmstudio_models if lmstudio_models else []\n",
        "default_model = model_options[0] if model_options else None\n",
        "\n",
        "# Widgets\n",
        "article_input = widgets.Text(value=str(DEFAULT_ARTICLE_ID), description='Article ID', layout=widgets.Layout(width='180px'))\n",
        "model_dropdown = widgets.Dropdown(options=model_options, value=default_model, description='LMStudio model', layout=widgets.Layout(width='420px'))\n",
        "refresh_models_button = widgets.Button(description='Refresh models', button_style='', tooltip='Refresh LMStudio model list')\n",
        "prompt_input = widgets.Textarea(value=default_prompt, description='Prompt', layout=widgets.Layout(width='100%', height='160px'))\n",
        "author_input = widgets.Text(value='Notebook User', description='Author', layout=widgets.Layout(width='250px'))\n",
        "force_toggle = widgets.Checkbox(value=False, description='Force regenerate')\n",
        "skip_matching_toggle = widgets.Checkbox(value=False, description='Skip matching phase')\n",
        "run_button = widgets.Button(description='Generate SIGMA', button_style='primary')\n",
        "save_json_button = widgets.Button(description='Save last JSON', button_style='success')\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def refresh_models(_=None):\n",
        "    global lmstudio_models\n",
        "    models = get_lmstudio_models()\n",
        "    if not models:\n",
        "        model_dropdown.options = []\n",
        "        model_dropdown.value = None\n",
        "        return\n",
        "    lmstudio_models = models\n",
        "    model_dropdown.options = models\n",
        "    model_dropdown.value = models[0]\n",
        "\n",
        "def on_run_clicked(_):\n",
        "    global last_response, results_df\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        article_id = article_input.value.strip()\n",
        "        model_id = model_dropdown.value\n",
        "        prompt_text = prompt_input.value.strip()\n",
        "        author = author_input.value.strip() or 'Notebook User'\n",
        "\n",
        "        if not model_id:\n",
        "            print('\u274c Select an LMStudio model first')\n",
        "            return\n",
        "\n",
        "        article = get_article(article_id)\n",
        "        if not article:\n",
        "            return\n",
        "\n",
        "        result = generate_sigma(article_id, model_id=model_id, prompt_override=prompt_text, author=author, force=force_toggle.value, skip_matching=skip_matching_toggle.value)\n",
        "        last_response = result or {}\n",
        "        if not result:\n",
        "            return\n",
        "\n",
        "        rules = result.get('rules') or []\n",
        "        valid_rules = sum(1 for r in rules if r.get('validated'))\n",
        "        coverage = result.get('coverage_summary', {})\n",
        "        matched = result.get('matched_rules') or []\n",
        "\n",
        "        print(f\"Rules returned: {len(rules)} (valid: {valid_rules})\")\n",
        "        if coverage:\n",
        "            print(f\"Coverage summary: {coverage}\")\n",
        "        if matched:\n",
        "            print(f\"Matched existing rules: {len(matched)}\")\n",
        "\n",
        "        summarize_rules(result)\n",
        "\n",
        "        conversation = (result.get('metadata') or {}).get('conversation') or []\n",
        "        if conversation:\n",
        "            print(f\"Conversation attempts: {len(conversation)}; last attempt valid={conversation[-1].get('all_valid')}\")\n",
        "\n",
        "        results_df.loc[len(results_df)] = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'article_id': article_id,\n",
        "            'lmstudio_model': model_id,\n",
        "            'rules': len(rules),\n",
        "            'valid_rules': valid_rules,\n",
        "            'cached': result.get('cached'),\n",
        "            'error': result.get('error'),\n",
        "        }\n",
        "\n",
        "def on_save_json(_):\n",
        "    if not last_response:\n",
        "        with output_area:\n",
        "            print('No response to save yet.')\n",
        "        return\n",
        "    fname = f\"sigma_generation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    Path(fname).write_text(json.dumps(last_response, indent=2))\n",
        "    with output_area:\n",
        "        print(f\"Saved last response to {fname}\")\n",
        "\n",
        "refresh_models_button.on_click(refresh_models)\n",
        "run_button.on_click(on_run_clicked)\n",
        "save_json_button.on_click(on_save_json)\n",
        "\n",
        "print('Controls ready \u2013 select article/model, tweak prompt, and click Generate SIGMA.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "display(widgets.VBox([\n",
        "    widgets.HTML('<h3>\ud83d\ude80 Generate SIGMA via API</h3>'),\n",
        "    widgets.HBox([article_input, refresh_models_button]),\n",
        "    model_dropdown,\n",
        "    prompt_input,\n",
        "    widgets.HBox([force_toggle, skip_matching_toggle]),\n",
        "    author_input,\n",
        "    widgets.HBox([run_button, save_json_button]),\n",
        "    output_area\n",
        "]))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Inspect accumulated runs\n",
        "if not results_df.empty:\n",
        "    display(results_df)\n",
        "else:\n",
        "    print('No runs yet.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Peek at last raw response\n",
        "if last_response:\n",
        "    print(json.dumps(last_response, indent=2)[:2000])\n",
        "else:\n",
        "    print('Run a generation first to see raw JSON.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}