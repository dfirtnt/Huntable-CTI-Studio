{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Testing Notebook\n",
    "Test different models via web API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in ./llm_env/lib/python3.13/site-packages (5.1.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./llm_env/lib/python3.13/site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in ./llm_env/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./llm_env/lib/python3.13/site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in ./llm_env/lib/python3.13/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in ./llm_env/lib/python3.13/site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./llm_env/lib/python3.13/site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in ./llm_env/lib/python3.13/site-packages (from sentence-transformers) (12.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./llm_env/lib/python3.13/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in ./llm_env/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./llm_env/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./llm_env/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./llm_env/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./llm_env/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in ./llm_env/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./llm_env/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./llm_env/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./llm_env/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./llm_env/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: setuptools in ./llm_env/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./llm_env/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./llm_env/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./llm_env/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./llm_env/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./llm_env/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./llm_env/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./llm_env/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./llm_env/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./llm_env/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.12)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./llm_env/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./llm_env/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Testing API connection...\n",
      "‚úÖ Connected! Article: Velociraptor WSUS Exploitation, Pt. I: WSUS-Up?...\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n",
    "\n",
    "import httpx\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "# Function to get article from API\n",
    "def get_article_from_api(article_id):\n",
    "    api_url = f\"http://localhost:8001/api/articles/{article_id}\"\n",
    "    try:\n",
    "        response = httpx.get(api_url, timeout=10.0)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"‚ùå API Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Connection error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test connection\n",
    "print(\"Testing API connection...\")\n",
    "article = get_article_from_api(68)\n",
    "if article:\n",
    "    print(f\"‚úÖ Connected! Article: {article['title'][:50]}...\")\n",
    "else:\n",
    "    print(\"‚ùå Connection failed\")\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LMStudio connection...\n",
      "‚úÖ Found 20 models\n",
      "First model: qwen/qwen3-coder-30b\n"
     ]
    }
   ],
   "source": [
    "# Get available models from LMStudio\n",
    "def get_lmstudio_models():\n",
    "    lmstudio_url = \"http://localhost:1234/v1\"\n",
    "    try:\n",
    "        response = httpx.get(f\"{lmstudio_url}/models\", timeout=5.0)\n",
    "        if response.status_code == 200:\n",
    "            models_data = response.json()\n",
    "            return [m[\"id\"] for m in models_data.get(\"data\", [])]\n",
    "        else:\n",
    "            print(f\"‚ùå LMStudio error: {response.status_code}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå LMStudio connection error: {e}\")\n",
    "        return []\n",
    "\n",
    "# Test LMStudio\n",
    "print(\"Testing LMStudio connection...\")\n",
    "models = get_lmstudio_models()\n",
    "print(f\"‚úÖ Found {len(models)} models\")\n",
    "if models:\n",
    "    print(f\"First model: {models[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangFuse tracing (optional)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from contextlib import nullcontext\n",
    "\n",
    "REPO_ROOT = Path(\".\").resolve()\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "try:\n",
    "    from src.utils.langfuse_client import (\n",
    "        is_langfuse_enabled,\n",
    "        trace_llm_call,\n",
    "        log_llm_completion,\n",
    "        log_llm_error,\n",
    "        trace_workflow_execution,\n",
    "        log_workflow_step,\n",
    "    )\n",
    "except Exception as lf_import_err:\n",
    "    print(f\"‚ö†Ô∏è LangFuse not available in notebook environment: {lf_import_err}\")\n",
    "    def is_langfuse_enabled():\n",
    "        return False\n",
    "    trace_llm_call = log_llm_completion = log_llm_error = trace_workflow_execution = log_workflow_step = None\n",
    "\n",
    "langfuse_context = {}\n",
    "\n",
    "def ensure_langfuse_context(article_id):\n",
    "    if not is_langfuse_enabled():\n",
    "        return None\n",
    "    import hashlib\n",
    "    import time\n",
    "\n",
    "    existing = (\n",
    "        langfuse_context.get(\"article_id\") == article_id\n",
    "        and langfuse_context.get(\"trace_id\")\n",
    "    )\n",
    "    if existing:\n",
    "        return langfuse_context\n",
    "\n",
    "    try:\n",
    "        article_id_int = int(article_id)\n",
    "    except Exception:\n",
    "        article_id_int = None\n",
    "\n",
    "    execution_id = int(time.time())\n",
    "    session_id = f\"notebook_article_{article_id}_{execution_id}\"\n",
    "    trace_id = hashlib.md5(f\"workflow_exec_{execution_id}\".encode()).hexdigest()\n",
    "\n",
    "    langfuse_context.update({\n",
    "        \"article_id\": article_id,\n",
    "        \"article_id_int\": article_id_int,\n",
    "        \"execution_id\": execution_id,\n",
    "        \"session_id\": session_id,\n",
    "        \"trace_id\": trace_id\n",
    "    })\n",
    "    return langfuse_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test LLM call with optional LangFuse tracing\n",
    "def test_llm(model, prompt, article, call_name=\"llm_call\", langfuse_ctx=None):\n",
    "    lmstudio_url = \"http://localhost:1234/v1\"\n",
    "\n",
    "    full_prompt = f\"\"\"Article Title: {article[\"title\"]}\n",
    "Article URL: {article.get(\"canonical_url\", \"\")}\n",
    "\n",
    "Article Content:\n",
    "{article[\"content\"][:4000]}...\n",
    "\n",
    "Task: {prompt}\"\"\"\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": full_prompt}]\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "\n",
    "    lf_ctx = langfuse_ctx if (langfuse_ctx and is_langfuse_enabled()) else None\n",
    "    lf_metadata = {\n",
    "        \"messages\": messages,\n",
    "        \"call_name\": call_name,\n",
    "        \"article_id\": article.get(\"id\") or article.get(\"article_id\"),\n",
    "        \"article_title\": article.get(\"title\", \"\"),\n",
    "    }\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    generation_cm = nullcontext(None)\n",
    "    if lf_ctx and trace_llm_call:\n",
    "        generation_cm = trace_llm_call(\n",
    "            name=call_name,\n",
    "            model=model,\n",
    "            execution_id=lf_ctx.get(\"execution_id\"),\n",
    "            article_id=lf_ctx.get(\"article_id_int\"),\n",
    "            trace_id=lf_ctx.get(\"trace_id\"),\n",
    "            session_id=lf_ctx.get(\"session_id\"),\n",
    "            metadata=lf_metadata\n",
    "        )\n",
    "\n",
    "    with generation_cm as generation:\n",
    "        try:\n",
    "            response = httpx.post(f\"{lmstudio_url}/chat/completions\", json=payload, timeout=60.0)\n",
    "            duration = time.perf_counter() - start\n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                content = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "                if lf_ctx and log_llm_completion:\n",
    "                    log_llm_completion(generation, messages, content, metadata=lf_metadata)\n",
    "                return {\"status\": \"success\", \"response\": content, \"length\": len(content), \"duration_sec\": duration}\n",
    "            else:\n",
    "                error_msg = f\"API Error: {response.status_code}\"\n",
    "                if lf_ctx and log_llm_error:\n",
    "                    log_llm_error(generation, Exception(error_msg), metadata=lf_metadata)\n",
    "                return {\"status\": \"error\", \"response\": error_msg, \"length\": 0, \"duration_sec\": duration}\n",
    "        except Exception as e:\n",
    "            duration = time.perf_counter() - start\n",
    "            if lf_ctx and log_llm_error:\n",
    "                log_llm_error(generation, e, metadata=lf_metadata)\n",
    "            return {\"status\": \"error\", \"response\": f\"Exception: {str(e)}\", \"length\": 0, \"duration_sec\": duration}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced LLM Testing\n",
    "Select multiple models, custom articles, and get CSV output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Load default CmdlineExtract prompt from repo files; fall back to a short default if missing.\n",
    "def load_cmdline_prompt():\n",
    "    candidates = [\n",
    "        Path(\"src/prompts/CmdlineExtract\"),\n",
    "        Path(\"prompts/CmdlineExtract\"),\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p.read_text().strip()\n",
    "    return \"\"\"You are a specialized extraction agent focused on extracting explicit Windows command-line observables from threat intelligence articles. Extract only literal Windows command lines with an executable/system utility plus at least one argument/switch/parameter/pipeline/redirection. Respond with a JSON object: {\"cmdline_items\": [...], \"count\": <int>, \"qa_corrections\": {\"removed\": [], \"added\": [], \"summary\": \"None.\"}}. Use double backslashes for Windows paths.\"\"\"\n",
    "\n",
    "# Load CmdLine QA prompt (mirrors workflow QA agent)\n",
    "def load_cmdline_qa_prompt():\n",
    "    candidates = [\n",
    "        Path(\"src/prompts/CmdLineQA\"),\n",
    "        Path(\"prompts/CmdLineQA\"),\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p.read_text().strip()\n",
    "    return \"Review extracted command-lines. If any are invalid or missing, provide added/removed entries in qa_corrections and return the corrected list. Respond with JSON matching {\\\"cmdline_items\\\": [...], \\\"count\\\": <int>, \\\"qa_corrections\\\": {\\\"removed\\\": [], \\\"added\\\": [], \\\"summary\\\": \\\"None.\\\"}}.\"\n",
    "\n",
    "CMDLINE_PROMPT = load_cmdline_prompt()\n",
    "CMDLINE_QA_PROMPT = load_cmdline_qa_prompt()\n",
    "\n",
    "# Extract count from model response JSON (only when properly formatted)\n",
    "def extract_count(response_text):\n",
    "    if not response_text or not isinstance(response_text, str):\n",
    "        return None\n",
    "    text = response_text.strip()\n",
    "    if text.startswith(\"```\"):\n",
    "        parts = text.split(\"\\n\")\n",
    "        if parts:\n",
    "            parts = parts[1:]\n",
    "            if parts and parts[-1].strip().startswith(\"```\"):\n",
    "                parts = parts[:-1]\n",
    "            text = \"\\n\".join(parts).strip()\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "    except Exception:\n",
    "        return None\n",
    "    count = data.get(\"count\")\n",
    "    if isinstance(count, int):\n",
    "        return count\n",
    "    items = data.get(\"cmdline_items\")\n",
    "    if isinstance(items, list):\n",
    "        return len(items)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced testing interface ready!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Global results\n",
    "results_df = pd.DataFrame(columns=[\"timestamp\", \"agent\", \"article_id\", \"article_title\", \"model\", \"prompt\", \"response\", \"response_length\", \"duration_sec\", \"status\", \"count\"])\n",
    "\n",
    "# UI Widgets\n",
    "article_input = widgets.Text(\n",
    "    value=\"68\",\n",
    "    placeholder=\"Enter article ID\",\n",
    "    description=\"Article ID:\",\n",
    "    layout=widgets.Layout(width=\"200px\")\n",
    ")\n",
    "\n",
    "model_select = widgets.SelectMultiple(\n",
    "    options=models if \"models\" in globals() else [],\n",
    "    description=\"Cmd Models:\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"150px\")\n",
    ")\n",
    "\n",
    "prompt_input = widgets.Textarea(\n",
    "    value=CMDLINE_PROMPT,\n",
    "    placeholder=\"Enter your prompt here...\",\n",
    "    description=\"Cmd Prompt:\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"120px\")\n",
    ")\n",
    "\n",
    "qa_model_select = widgets.SelectMultiple(\n",
    "    options=models if \"models\" in globals() else [],\n",
    "    description=\"QA Models:\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"150px\")\n",
    ")\n",
    "\n",
    "qa_prompt_input = widgets.Textarea(\n",
    "    value=CMDLINE_QA_PROMPT,\n",
    "    placeholder=\"Enter QA prompt...\",\n",
    "    description=\"QA Prompt:\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"120px\")\n",
    ")\n",
    "\n",
    "run_button = widgets.Button(\n",
    "    description=\"Run Cmd Tests\",\n",
    "    button_style=\"primary\",\n",
    "    tooltip=\"Run LLM tests with selected parameters\"\n",
    ")\n",
    "\n",
    "qa_run_button = widgets.Button(\n",
    "    description=\"Run QA Tests\",\n",
    "    button_style=\"info\",\n",
    "    tooltip=\"Run QA tests with selected parameters\"\n",
    ")\n",
    "\n",
    "csv_button = widgets.Button(\n",
    "    description=\"Save CSV\",\n",
    "    button_style=\"success\",\n",
    "    tooltip=\"Save results to CSV file\"\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "print(\"Enhanced testing interface ready!\")\n",
    "\n",
    "# Holds latest cmdline extraction outputs for QA chaining\n",
    "last_cmdline_outputs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Button handlers connected!\n"
     ]
    }
   ],
   "source": [
    "# Enhanced testing functions\n",
    "\n",
    "def run_enhanced_tests(article_id, selected_models, prompt):\n",
    "    global results_df, last_cmdline_outputs\n",
    "    last_cmdline_outputs = []\n",
    "    lf_ctx = ensure_langfuse_context(article_id)\n",
    "    trace_cm = trace = None\n",
    "    try:\n",
    "        if lf_ctx and trace_workflow_execution:\n",
    "            trace_cm = trace_workflow_execution(\n",
    "                execution_id=lf_ctx.get(\"execution_id\"),\n",
    "                article_id=lf_ctx.get(\"article_id_int\") or 0,\n",
    "                session_id=lf_ctx.get(\"session_id\"),\n",
    "                user_id=\"notebook_llm_tester\"\n",
    "            )\n",
    "            trace = trace_cm.__enter__()\n",
    "\n",
    "        print(f\"Getting article {article_id}...\")\n",
    "        article = get_article_from_api(article_id)\n",
    "        if not article:\n",
    "            print(f\"‚ùå Article {article_id} not found\")\n",
    "            return\n",
    "\n",
    "        print(f\"‚úÖ Article: {article['title'][:60]}...\")\n",
    "        print(f\"üìè Content: {len(article['content'])} chars\")\n",
    "        print(f\"ü§ñ Testing {len(selected_models)} models √ó 1 prompt (Cmdline Extract)\")\n",
    "        print()\n",
    "\n",
    "        for i, model in enumerate(selected_models, 1):\n",
    "            model_name = model.split('/')[-1]\n",
    "            print(f\"üß† Cmd Agent Model {i}/{len(selected_models)}: {model_name}\")\n",
    "\n",
    "            result = test_llm(model, prompt, article, call_name=\"cmdline_extract\", langfuse_ctx=lf_ctx)\n",
    "\n",
    "            results_df.loc[len(results_df)] = {\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"agent\": \"CmdlineExtract\",\n",
    "                \"article_id\": article_id,\n",
    "                \"article_title\": article['title'][:100],\n",
    "                \"model\": model,\n",
    "                \"prompt\": prompt,\n",
    "                \"response\": result['response'],\n",
    "                \"response_length\": result['length'],\n",
    "                \"count\": extract_count(result.get('response', '')),\n",
    "                \"duration_sec\": result.get('duration_sec', 0.0),\n",
    "                \"status\": result['status']\n",
    "            }\n",
    "\n",
    "            if trace and log_workflow_step:\n",
    "                log_workflow_step(\n",
    "                    trace,\n",
    "                    f\"cmdline_extract_{model_name}\",\n",
    "                    step_result={\"status\": result['status'], \"count\": extract_count(result.get('response', '')), \"duration_sec\": result.get('duration_sec', 0.0)},\n",
    "                    metadata={\"model\": model}\n",
    "                )\n",
    "\n",
    "            if result['status'] == 'success':\n",
    "                last_cmdline_outputs.append({\n",
    "                    \"model\": model,\n",
    "                    \"response\": result['response']\n",
    "                })\n",
    "                print(f\"    ‚úÖ Success ({result['length']} chars) in {result.get('duration_sec',0):.2f}s\")\n",
    "            else:\n",
    "                print(f\"    ‚ùå {result['response']}\")\n",
    "\n",
    "        print(f\"üìä Completed {len(selected_models)} Cmd tests!\")\n",
    "        print(f\"Results stored in DataFrame ({len(results_df)} total rows)\")\n",
    "    finally:\n",
    "        if trace_cm:\n",
    "            trace_cm.__exit__(None, None, None)\n",
    "\n",
    "\n",
    "def run_cmdline_qa_tests(article_id, selected_models, prompt):\n",
    "    global results_df, last_cmdline_outputs\n",
    "    lf_ctx = ensure_langfuse_context(article_id)\n",
    "    trace_cm = trace = None\n",
    "    try:\n",
    "        if lf_ctx and trace_workflow_execution:\n",
    "            trace_cm = trace_workflow_execution(\n",
    "                execution_id=lf_ctx.get(\"execution_id\"),\n",
    "                article_id=lf_ctx.get(\"article_id_int\") or 0,\n",
    "                session_id=lf_ctx.get(\"session_id\"),\n",
    "                user_id=\"notebook_llm_tester\"\n",
    "            )\n",
    "            trace = trace_cm.__enter__()\n",
    "\n",
    "        print(f\"Getting article {article_id} for QA...\")\n",
    "        article = get_article_from_api(article_id)\n",
    "        if not article:\n",
    "            print(f\"‚ùå Article {article_id} not found\")\n",
    "            return\n",
    "\n",
    "        if not last_cmdline_outputs:\n",
    "            print(\"‚ö†Ô∏è No extractor outputs available. Run Cmdline Extract tests first.\")\n",
    "\n",
    "        extraction_context = \"\\n\\n\".join(\n",
    "            [f\"Model: {item['model']}\\nOutput:\\n{item['response']}\" for item in last_cmdline_outputs]\n",
    "        ) if last_cmdline_outputs else \"No extractor outputs captured.\"\n",
    "        \n",
    "\n",
    "        print(f\"ü§ñ Testing {len(selected_models)} models √ó 1 prompt (CmdLine QA)\")\n",
    "        print()\n",
    "\n",
    "        if trace and log_workflow_step:\n",
    "            log_workflow_step(\n",
    "                trace,\n",
    "                \"cmdline_qa_context\",\n",
    "                step_result={\n",
    "                    \"has_extractor_outputs\": bool(last_cmdline_outputs),\n",
    "                    \"extractor_models\": [item['model'] for item in last_cmdline_outputs]\n",
    "                },\n",
    "                metadata={\"agent\": \"CmdLineQA\"}\n",
    "            )\n",
    "\n",
    "        for i, model in enumerate(selected_models, 1):\n",
    "            model_name = model.split('/')[-1]\n",
    "            print(f\"üß† QA Agent Model {i}/{len(selected_models)}: {model_name}\")\n",
    "\n",
    "            qa_prompt_with_context = f\"\"\"{prompt}\n",
    "\n",
    "Extracted command-lines to evaluate:\n",
    "{extraction_context}\"\"\"\n",
    "            result = None\n",
    "            max_attempts = 2\n",
    "            for attempt in range(1, max_attempts + 1):\n",
    "                result = test_llm(model, qa_prompt_with_context, article, call_name=\"cmdline_qa\", langfuse_ctx=lf_ctx)\n",
    "                if result.get('status') == 'success' and result.get('response', '').strip():\n",
    "                    break\n",
    "                if attempt < max_attempts:\n",
    "                    print(f\"    ‚ö†Ô∏è QA attempt {attempt} returned empty/failed (status={result.get('status')}, len={len(result.get('response',''))}); retrying...\")\n",
    "\n",
    "            results_df.loc[len(results_df)] = {\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"agent\": \"CmdLineQA\",\n",
    "                \"article_id\": article_id,\n",
    "                \"article_title\": article['title'][:100],\n",
    "                \"model\": model,\n",
    "                \"prompt\": qa_prompt_with_context,\n",
    "                \"response\": result.get('response', ''),\n",
    "                \"count\": extract_count(result.get('response', '')),\n",
    "                \"response_length\": result.get('length', 0),\n",
    "                \"duration_sec\": result.get('duration_sec', 0.0),\n",
    "                \"status\": result.get('status')\n",
    "            }\n",
    "\n",
    "            if trace and log_workflow_step:\n",
    "                log_workflow_step(\n",
    "                    trace,\n",
    "                    f\"cmdline_qa_{model_name}\",\n",
    "                    step_result={\"status\": result.get('status'), \"count\": extract_count(result.get('response', '')), \"duration_sec\": result.get('duration_sec', 0.0)},\n",
    "                    metadata={\"model\": model}\n",
    "                )\n",
    "\n",
    "            if result.get('status') == 'success':\n",
    "                print(f\"    ‚úÖ QA Success ({result.get('length',0)} chars) in {result.get('duration_sec',0):.2f}s\")\n",
    "            else:\n",
    "                print(f\"    ‚ùå {result.get('response','')}\")\n",
    "\n",
    "        print(f\"üìä Completed {len(selected_models)} QA tests!\")\n",
    "        print(f\"Results stored in DataFrame ({len(results_df)} total rows)\")\n",
    "    finally:\n",
    "        if trace_cm:\n",
    "            trace_cm.__exit__(None, None, None)\n",
    "\n",
    "# Button handlers\n",
    "def on_run_clicked(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        article_id = article_input.value.strip()\n",
    "        selected_models = list(model_select.value)\n",
    "        prompt = prompt_input.value.strip()\n",
    "\n",
    "        if not article_id:\n",
    "            print(\"‚ùå Please enter an article ID\")\n",
    "            return\n",
    "        if not selected_models:\n",
    "            print(\"‚ùå Please select at least one model\")\n",
    "            return\n",
    "        if not prompt:\n",
    "            print(\"‚ùå Please enter a prompt\")\n",
    "            return\n",
    "\n",
    "        print(\"üöÄ Starting Cmdline Extract tests...\")\n",
    "        run_enhanced_tests(article_id, selected_models, prompt)\n",
    "\n",
    "\n",
    "def on_qa_run_clicked(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        article_id = article_input.value.strip()\n",
    "        selected_models = list(qa_model_select.value)\n",
    "        prompt = qa_prompt_input.value.strip()\n",
    "\n",
    "        if not article_id:\n",
    "            print(\"‚ùå Please enter an article ID\")\n",
    "            return\n",
    "        if not selected_models:\n",
    "            print(\"‚ùå Please select at least one QA model\")\n",
    "            return\n",
    "        if not prompt:\n",
    "            print(\"‚ùå Please enter a QA prompt\")\n",
    "            return\n",
    "\n",
    "        print(\"üöÄ Starting CmdLine QA tests...\")\n",
    "        run_cmdline_qa_tests(article_id, selected_models, prompt)\n",
    "\n",
    "\n",
    "def on_csv_clicked(b):\n",
    "    with output_area:\n",
    "        if results_df.empty:\n",
    "            print(\"‚ùå No results to save\")\n",
    "            return\n",
    "\n",
    "        filename = f\"llm_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}\" + \".csv\"\n",
    "        results_df.to_csv(filename, index=False)\n",
    "        print(f\"‚úÖ Saved {len(results_df)} results to {filename}\")\n",
    "\n",
    "# Connect handlers\n",
    "run_button.on_click(on_run_clicked)\n",
    "qa_run_button.on_click(on_qa_run_clicked)\n",
    "csv_button.on_click(on_csv_clicked)\n",
    "\n",
    "print(\"Button handlers connected!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd37353f1f8484a9a5d4360260ed7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üöÄ Enhanced LLM Testing</h3>'), Text(value='68', description='Article ID:', layo‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced UI ready! Select your options and click Run Tests.\n"
     ]
    }
   ],
   "source": [
    "# Display enhanced UI\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üöÄ Enhanced LLM Testing</h3>\"),\n",
    "    article_input,\n",
    "    widgets.HTML(\"<strong>Cmdline Extract</strong>\"),\n",
    "    model_select,\n",
    "    prompt_input,\n",
    "    widgets.HBox([run_button, csv_button]),\n",
    "    widgets.HTML(\"<strong>CmdLine QA</strong>\"),\n",
    "    qa_model_select,\n",
    "    qa_prompt_input,\n",
    "    qa_run_button,\n",
    "    output_area\n",
    "]))\n",
    "\n",
    "print(\"Enhanced UI ready! Select your options and click Run Tests.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results yet. Run some tests first!\n"
     ]
    }
   ],
   "source": [
    "# View current results\n",
    "if not results_df.empty:\n",
    "    print(f\"üìä Current results: {len(results_df)} tests\")\n",
    "    display(results_df)\n",
    "else:\n",
    "    print(\"No results yet. Run some tests first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cmdline_items': [],\n",
       " 'count': 0,\n",
       " 'qa_enabled': False,\n",
       " 'candidates': ['WSUSService.exe before running the Windows installer (as seen via a Service Control Manager/7036 message stating Windows Installer,running ) and then installing a malicious MSI package from s3[.]wasabisys[.]com . Figure 1 illustrates the results of searching for the domain on VirusTotal. Figure 1: VirusTotal search for the domain wasabisys[.]com linked to the malicious MSI package As seen in the Windows Event Log records below, the threat actor then installed Velociraptor, which was configured to communicate with the endpoint update[.]githubtestbak[.]workers[.]dev . MsiInstaller/1040;https://s3.wasabisys.com/kiessler/v4.msi,3348,(NULL),(NULL),(NULL),(NULL), Service Control Manager/7045;Velociraptor Service,\"C:\\\\Program Files\\\\Velociraptor\\\\Velociraptor.exe\" --config \"C:\\\\Program Files\\\\Velociraptor\\\\/client.config.yaml\" service run ,user mode service,auto start,LocalSystem Service Control Manager/7036;Velociraptor Service,running Velociraptor/1;Starting service Velociraptor MsiInstaller/11707;Product: Velociraptor -- Installation completed successfully.,(NULL),(NULL),(NULL),(NULL),(NULL), Velociraptor was installed via the following binary path: Velociraptor/1000;\"Velociraptor startup ARGV: [\"\"C:\\\\Program Files\\\\Velociraptor\\\\Velociraptor.exe\"\",\"\"--config\"\",\"\"C:\\\\Program Files\\\\Velociraptor\\\\/client.config.yaml\"\",\"\"service\"\",\"\"run\"\"],\" During the investigation into the incident, we found that even though the first attempt to install Velociraptor succeeded, there were two more subsequent attempts to run the same command to install the open source tool from the same location. After the threat actor installed Velociraptor, we observed a number of base64-encoded PowerShell commands, which were child processes of Velociraptor.exe, such as the following: C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe -ExecutionPolicy Unrestricted -encodedCommand cQB1AHMAZQByAA== Each of the observed PowerShell commands varied only in the encoded commands; the command line switches and their positions in the command line were consistent across all commands. These commands launched a series of discovery queries, allowing the threat actor to gather information about users, running services, configurations, and more. \"C:\\\\Windows\\\\system32\\\\net.exe\" group \"domain computers\" /do \"C:\\\\Windows\\\\system32\\\\quser.exe\" \"C:\\\\Windows\\\\system32\\\\setspn.exe\" -Q VeeamBackupSVC/* \"C:\\\\Windows\\\\system32\\\\ipconfig.exe\" /al Figure 2: EDR signals showing the threat actor installing an MSI package, running Velociraptor, and performing discovery commands At this point, the threat actor s activity was contained by Huntress SOC analysts. Conclusion Velociraptor is only the latest legitimate tool that threat actors are abusing. While this is specifically for incident response, many of the tools that have previously been misused in attacks include dual-use penetration testing frameworks, such as Cobalt Strike, Mimikatz, Metasploit, and PowerSploit, as highlighted in the Huntress 2025 Cyber Threat Report . We ve seen threat actors use legitimate tools long enough to know that Velociraptor won t be the first dual-use, open-source tool that will pop up in attacks - nor will it be the last. However, by closely tracking the behavior in incidents that involve Velociraptor, we can get a better understanding of how threat actors are deploying these tools in victim environments. Huntress has seen Velociraptor in a number of other incidents over the past few months. For an additional deep view and insights into the misuse of the tool, stay tuned for part 2 of this blog series. Indicators of Compromise (IOCs) Item Description s3[.]wasabisys[.]com Domain from which MSI package was retrieved update[.]githubtestbak[.]workers[.]dev Velociraptor C2'],\n",
       " 'filtered': [],\n",
       " 'literal': []}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hybrid cmdline extraction on Article 68 using current YAML patterns\n",
    "import json\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "from src.extractors.regex_windows import extract_candidate_lines\n",
    "from src.extractors.encoder_classifier import classify_candidates\n",
    "from src.extractors.hybrid_cmdline_extractor import literal_filter, is_qa_enabled\n",
    "from src.extractors.qa_validator import qa_validate\n",
    "\n",
    "def get_article_content(article_id: int) -> str:\n",
    "    cmd = [\n",
    "        \"docker\", \"exec\", \"-i\", \"cti_postgres\",\n",
    "        \"psql\", \"-U\", \"cti_user\", \"-d\", \"cti_scraper\",\n",
    "        \"-t\", \"-A\", \"-c\", f\"SELECT content FROM articles WHERE id={article_id};\"\n",
    "    ]\n",
    "    return subprocess.check_output(cmd).decode().strip()\n",
    "\n",
    "def run_hybrid(article_id: int = 68):\n",
    "    content = get_article_content(article_id)\n",
    "    candidates = extract_candidate_lines(content)\n",
    "    filtered = classify_candidates(candidates)\n",
    "    literal = literal_filter(filtered, content)\n",
    "    qa_enabled = is_qa_enabled()\n",
    "    final = qa_validate(literal, content) if qa_enabled else literal\n",
    "\n",
    "    return {\n",
    "        \"cmdline_items\": final,\n",
    "        \"count\": len(final),\n",
    "        \"qa_enabled\": qa_enabled,\n",
    "        \"candidates\": candidates,\n",
    "        \"filtered\": filtered,\n",
    "        \"literal\": literal,\n",
    "    }\n",
    "\n",
    "result = run_hybrid(68)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exe_with_args': '(?:\"?[A-Za-z]:\\\\\\\\+[^\"\\\\s]+\\\\.\\\\w{3,4}\"?(?:\\\\s+[^\\\\r\\\\n]+))', 'bare_exe_with_args': '(?:[A-Za-z0-9_\\\\-]+\\\\.exe)(?:\\\\s+[^\\\\r\\\\n]+)', 'powershell': '(?:powershell(?:\\\\.exe)?)\\\\s+[^\\\\r\\\\n]+', 'system32_utils': '(?:\"?C:\\\\\\\\+Windows\\\\\\\\+System32\\\\\\\\+(?:net|ipconfig|setspn|quser)\\\\.exe\"?\\\\s+[^\\\\r\\\\n]+)', 'quoted_with_spaces': '\"[A-Za-z]:\\\\\\\\+[^\"\\\\r\\\\n]+?\\\\.\\\\w{3,4}\"(?:\\\\s+[^\\\\r\\\\n]+)'}\n",
      "{'exe_with_args': '\"?[A-Za-z]:\\\\\\\\\\\\\\\\[^\"\\\\r\\\\n]+\\\\.\\\\w{2,5}\"?(?:\\\\s+[^\\\\r\\\\n]+)', 'bare_exe_with_args': '(?i)(?:^|\\\\s)([A-Za-z0-9_\\\\-]+\\\\.exe)(?:\\\\s+[^\\\\r\\\\n]+)', 'powershell': '(?i)(?:\"?[A-Za-z]:\\\\\\\\\\\\\\\\[^\"\\\\r\\\\n]*\\\\\\\\(?:powershell|pwsh)(?:\\\\.exe)?\"?)\\\\s+[^\\\\r\\\\n]+', 'system32_utils': '(?i)\"?C:\\\\\\\\\\\\\\\\Windows\\\\\\\\\\\\\\\\System32\\\\\\\\\\\\\\\\(?:net|ipconfig|setspn|quser)\\\\.exe\"?\\\\s+[^\\\\r\\\\n]+', 'quoted_with_spaces': '\"[A-Za-z]:\\\\\\\\\\\\\\\\[^\"\\\\r\\\\n]+\\\\.\\\\w{2,5}\"(?:\\\\s+[^\\\\r\\\\n]+)'}\n",
      "['WSUSService.exe before running the Windows installer (as seen via a Service Control Manager/7036 message stating Windows Installer', 'Velociraptor.exe\\n such as the following: C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe -ExecutionPolicy Unrestricted -encodedCommand cQB1AHMAZQByAA== Each of the observed PowerShell commands varied only in the encoded commands']\n"
     ]
    }
   ],
   "source": [
    "from src.extractors import regex_windows\n",
    "from src.extractors.regex_windows import extract_candidate_lines\n",
    "import subprocess\n",
    "\n",
    "def _get_article_content(article_id: int) -> str:\n",
    "    cmd = [\n",
    "        'docker','exec','-i','cti_postgres',\n",
    "        'psql','-U','cti_user','-d','cti_scraper',\n",
    "        '-t','-A','-c', f'SELECT content FROM articles WHERE id={article_id};'\n",
    "    ]\n",
    "    return subprocess.check_output(cmd).decode().strip()\n",
    "\n",
    "def split_log_blob(text: str) -> str:\n",
    "    for sep in [';','\"','\\n',',']:\n",
    "        text = text.replace(sep, '\\n')\n",
    "    return text\n",
    "\n",
    "content = _get_article_content(68)\n",
    "preprocessed = split_log_blob(content)\n",
    "candidates = extract_candidate_lines(preprocessed)\n",
    "\n",
    "print(regex_windows.DEFAULT_PATTERNS)\n",
    "print(regex_windows._load_external_patterns())\n",
    "print(candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qa_enabled': False,\n",
       " 'candidates': ['node.exe\\n) and actor_process_command_line contains',\n",
       "  'node.exe\\n ) and actor_process_command_line contains',\n",
       "  'curl.exe\\n\\n\\nwget',\n",
       "  'wget.exe\\n\\n\\nwhoami',\n",
       "  'arp.exe\\n\\n\\nat.exe',\n",
       "  'hostname.exe\\n\\n\\nnbstat.exe',\n",
       "  'netsh.exe\\n\\n\\nnetstat.exe',\n",
       "  'nslookup.exe\\n\\n\\nping.exe',\n",
       "  'query.exe\\n\\n\\nsysteminfo.exe',\n",
       "  'tasklist.exe\\n\\n\\ntraceroute.exe',\n",
       "  'whoami.exe\\n\\n\\nwhois.exe',\n",
       "  'quser.exe\\n\\n\\nqwinsta.exe',\n",
       "  'nltest.exe\\n\\n\\ncsvde.exe',\n",
       "  'wevtutil.exe\\n\\n\\ndriverquery.exe',\n",
       "  'nbtscan.exe\\n\\n\\nntdsutil.exe',\n",
       "  'vssadmin.exe\\n\\n\\ndsquery.exe',\n",
       "  'adfind.exe\\n\\n\\nklist.exe',\n",
       "  'vssvc.exe\\n) | comp count_distinct(action_process_image_name) as num_procs',\n",
       "  'curl.exe\\n \\n \\nwget',\n",
       "  'wget.exe\\n \\n \\nwhoami',\n",
       "  'arp.exe\\n \\n \\nat.exe',\n",
       "  'hostname.exe\\n \\n \\nnbstat.exe',\n",
       "  'netsh.exe\\n \\n \\nnetstat.exe',\n",
       "  'nslookup.exe\\n \\n \\nping.exe',\n",
       "  'query.exe\\n \\n \\nsysteminfo.exe',\n",
       "  'tasklist.exe\\n \\n \\ntraceroute.exe',\n",
       "  'whoami.exe\\n \\n \\nwhois.exe',\n",
       "  'quser.exe\\n \\n \\nqwinsta.exe',\n",
       "  'nltest.exe\\n \\n \\ncsvde.exe',\n",
       "  'wevtutil.exe\\n \\n \\ndriverquery.exe',\n",
       "  'nbtscan.exe\\n \\n \\nntdsutil.exe',\n",
       "  'vssadmin.exe\\n \\n \\ndsquery.exe',\n",
       "  'adfind.exe\\n \\n \\nklist.exe',\n",
       "  'vssvc.exe\\n ) | comp count_distinct ( action_process_image_name ) as num_procs',\n",
       "  'node.exe\\n) and causality_actor_process_command_line contains',\n",
       "  'cmd.exe\\n\\n\\npowershell.exe',\n",
       "  'wget.exe\\n) 1 2 3 4 5 6 7 // Description: Identifies a specific causality chain where Node.js spawns a shell (cmd/bash/powershell)',\n",
       "  'node.exe\\n ) and causality_actor_process_command_line contains',\n",
       "  'cmd.exe\\n \\n \\npowershell.exe',\n",
       "  'wget.exe\\n ) Conclusion The critical distinction of these vulnerabilities is their nature as a deterministic logic flaw in the Flight protocol'],\n",
       " 'filtered': ['node.exe\\n) and actor_process_command_line contains',\n",
       "  'node.exe\\n ) and actor_process_command_line contains',\n",
       "  'curl.exe\\n\\n\\nwget',\n",
       "  'wget.exe\\n\\n\\nwhoami',\n",
       "  'curl.exe\\n \\n \\nwget',\n",
       "  'wget.exe\\n \\n \\nwhoami',\n",
       "  'node.exe\\n) and causality_actor_process_command_line contains',\n",
       "  'wget.exe\\n) 1 2 3 4 5 6 7 // Description: Identifies a specific causality chain where Node.js spawns a shell (cmd/bash/powershell)',\n",
       "  'node.exe\\n ) and causality_actor_process_command_line contains'],\n",
       " 'literal': [],\n",
       " 'cmdline_items': [],\n",
       " 'count': 0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hybrid cmdline extraction with YAML overrides + log-line splitting (updated)\n",
    "import subprocess\n",
    "from src.extractors.regex_windows import extract_candidate_lines\n",
    "from src.extractors.encoder_classifier import classify_candidates\n",
    "from src.extractors.hybrid_cmdline_extractor import literal_filter, is_qa_enabled\n",
    "from src.extractors.qa_validator import qa_validate\n",
    "\n",
    "def get_article_content(article_id: int) -> str:\n",
    "    cmd = [\n",
    "        'docker', 'exec', '-i', 'cti_postgres',\n",
    "        'psql', '-U', 'cti_user', '-d', 'cti_scraper',\n",
    "        '-t', '-A', '-c', f\"SELECT content FROM articles WHERE id={article_id};\"\n",
    "    ]\n",
    "    return subprocess.check_output(cmd).decode().strip()\n",
    "\n",
    "def split_log_blob(text: str) -> str:\n",
    "    # Break long log rows into smaller tokens so regexes can match embedded commands\n",
    "    for sep in [';', '\"', '\\n', ',']:\n",
    "        text = text.replace(sep, '\\n')\n",
    "    return text\n",
    "\n",
    "def run_hybrid(article_id: int = 68):\n",
    "    content = get_article_content(article_id)\n",
    "    preprocessed = split_log_blob(content)\n",
    "\n",
    "    candidates = extract_candidate_lines(preprocessed)\n",
    "    filtered = classify_candidates(candidates)\n",
    "    literal = literal_filter(filtered, content)\n",
    "    qa_enabled = is_qa_enabled()\n",
    "    final = qa_validate(literal, content) if qa_enabled else literal\n",
    "\n",
    "    return {\n",
    "        'qa_enabled': qa_enabled,\n",
    "        'candidates': candidates,\n",
    "        'filtered': filtered,\n",
    "        'literal': literal,\n",
    "        'cmdline_items': final,\n",
    "        'count': len(final),\n",
    "    }\n",
    "\n",
    "result = run_hybrid(243)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFAULT_PATTERNS: {'exe_with_args': '(?:\"?[A-Za-z]:\\\\\\\\+[^\"\\\\s]+\\\\.\\\\w{3,4}\"?(?:\\\\s+[^\\\\r\\\\n]+))', 'bare_exe_with_args': '(?:[A-Za-z0-9_\\\\-]+\\\\.exe)(?:\\\\s+[^\\\\r\\\\n]+)', 'powershell': '(?:powershell(?:\\\\.exe)?)\\\\s+[^\\\\r\\\\n]+', 'system32_utils': '(?:\"?C:\\\\\\\\+Windows\\\\\\\\+System32\\\\\\\\+(?:net|ipconfig|setspn|quser)\\\\.exe\"?\\\\s+[^\\\\r\\\\n]+)', 'quoted_with_spaces': '\"[A-Za-z]:\\\\\\\\+[^\"\\\\r\\\\n]+?\\\\.\\\\w{3,4}\"(?:\\\\s+[^\\\\r\\\\n]+)'}\n",
      "YAML_PATTERNS   : {'exe_with_args': '\"?[A-Za-z]:\\\\\\\\\\\\\\\\[^\"\\\\r\\\\n]+\\\\.\\\\w{2,5}\"?(?:\\\\s+[^\\\\r\\\\n]+)', 'bare_exe_with_args': '(?i)(?:^|\\\\s)([A-Za-z0-9_\\\\-]+\\\\.exe)(?:\\\\s+[^\\\\r\\\\n]+)', 'powershell': '(?i)(?:\"?[A-Za-z]:\\\\\\\\\\\\\\\\[^\"\\\\r\\\\n]*\\\\\\\\(?:powershell|pwsh)(?:\\\\.exe)?\"?)\\\\s+[^\\\\r\\\\n]+', 'system32_utils': '(?i)\"?C:\\\\\\\\\\\\\\\\Windows\\\\\\\\\\\\\\\\System32\\\\\\\\\\\\\\\\(?:net|ipconfig|setspn|quser)\\\\.exe\"?\\\\s+[^\\\\r\\\\n]+', 'quoted_with_spaces': '\"[A-Za-z]:\\\\\\\\\\\\\\\\[^\"\\\\r\\\\n]+\\\\.\\\\w{2,5}\"(?:\\\\s+[^\\\\r\\\\n]+)'}\n",
      "\n",
      "Candidates (raw): ['WSUSService.exe before running the Windows installer (as seen via a Service Control Manager/7036 message stating Windows Installer', 'Velociraptor.exe\\n such as the following: C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe -ExecutionPolicy Unrestricted -encodedCommand cQB1AHMAZQByAA== Each of the observed PowerShell commands varied only in the encoded commands']\n",
      "After classifier: ['Velociraptor.exe\\n such as the following: C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe -ExecutionPolicy Unrestricted -encodedCommand cQB1AHMAZQByAA== Each of the observed PowerShell commands varied only in the encoded commands']\n",
      "After literal   : []\n",
      "QA enabled      : False\n",
      "Final cmdlines  : []\n",
      "Count           : 0\n"
     ]
    }
   ],
   "source": [
    "# Inspect current regex patterns and hybrid pipeline outputs for article 68\n",
    "from src.extractors import regex_windows\n",
    "from src.extractors.regex_windows import extract_candidate_lines\n",
    "from src.extractors.encoder_classifier import classify_candidates\n",
    "from src.extractors.hybrid_cmdline_extractor import literal_filter, is_qa_enabled\n",
    "from src.extractors.qa_validator import qa_validate\n",
    "import subprocess\n",
    "\n",
    "def _get_article_content(article_id: int) -> str:\n",
    "    cmd = [\n",
    "        'docker', 'exec', '-i', 'cti_postgres',\n",
    "        'psql', '-U', 'cti_user', '-d', 'cti_scraper',\n",
    "        '-t', '-A', '-c', f\"SELECT content FROM articles WHERE id={article_id};\"\n",
    "    ]\n",
    "    return subprocess.check_output(cmd).decode().strip()\n",
    "\n",
    "def split_log_blob(text: str) -> str:\n",
    "    for sep in [';', '\"', '\\n', ',']:\n",
    "        text = text.replace(sep, '\\n')\n",
    "    return text\n",
    "\n",
    "content = _get_article_content(68)\n",
    "preprocessed = split_log_blob(content)\n",
    "\n",
    "print('DEFAULT_PATTERNS:', regex_windows.DEFAULT_PATTERNS)\n",
    "print('YAML_PATTERNS   :', regex_windows._load_external_patterns())\n",
    "\n",
    "candidates = extract_candidate_lines(preprocessed)\n",
    "filtered = classify_candidates(candidates)\n",
    "literal = literal_filter(filtered, content)\n",
    "qa_enabled = is_qa_enabled()\n",
    "final = qa_validate(literal, content) if qa_enabled else literal\n",
    "\n",
    "print('\\nCandidates (raw):', candidates)\n",
    "print('After classifier:', filtered)\n",
    "print('After literal   :', literal)\n",
    "print('QA enabled      :', qa_enabled)\n",
    "print('Final cmdlines  :', final)\n",
    "print('Count           :', len(final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 40 candidates:\n",
      "\n",
      "- node.exe\n",
      "\n",
      " and actor_process_command_line contains\n",
      "- node.exe\n",
      " \n",
      " and actor_process_command_line contains\n",
      "- curl.exe\n",
      "\n",
      "\n",
      "wget\n",
      "- wget.exe\n",
      "\n",
      "\n",
      "whoami\n",
      "- arp.exe\n",
      "\n",
      "\n",
      "at.exe\n",
      "- hostname.exe\n",
      "\n",
      "\n",
      "nbstat.exe\n",
      "- netsh.exe\n",
      "\n",
      "\n",
      "netstat.exe\n",
      "- nslookup.exe\n",
      "\n",
      "\n",
      "ping.exe\n",
      "- query.exe\n",
      "\n",
      "\n",
      "systeminfo.exe\n",
      "- tasklist.exe\n",
      "\n",
      "\n",
      "traceroute.exe\n",
      "- whoami.exe\n",
      "\n",
      "\n",
      "whois.exe\n",
      "- quser.exe\n",
      "\n",
      "\n",
      "qwinsta.exe\n",
      "- nltest.exe\n",
      "\n",
      "\n",
      "csvde.exe\n",
      "- wevtutil.exe\n",
      "\n",
      "\n",
      "driverquery.exe\n",
      "- nbtscan.exe\n",
      "\n",
      "\n",
      "ntdsutil.exe\n",
      "- vssadmin.exe\n",
      "\n",
      "\n",
      "dsquery.exe\n",
      "- adfind.exe\n",
      "\n",
      "\n",
      "klist.exe\n",
      "- vssvc.exe\n",
      "\n",
      " | comp count_distinct\n",
      "- curl.exe\n",
      " \n",
      " \n",
      "wget\n",
      "- wget.exe\n",
      " \n",
      " \n",
      "whoami\n",
      "- arp.exe\n",
      " \n",
      " \n",
      "at.exe\n",
      "- hostname.exe\n",
      " \n",
      " \n",
      "nbstat.exe\n",
      "- netsh.exe\n",
      " \n",
      " \n",
      "netstat.exe\n",
      "- nslookup.exe\n",
      " \n",
      " \n",
      "ping.exe\n",
      "- query.exe\n",
      " \n",
      " \n",
      "systeminfo.exe\n",
      "- tasklist.exe\n",
      " \n",
      " \n",
      "traceroute.exe\n",
      "- whoami.exe\n",
      " \n",
      " \n",
      "whois.exe\n",
      "- quser.exe\n",
      " \n",
      " \n",
      "qwinsta.exe\n",
      "- nltest.exe\n",
      " \n",
      " \n",
      "csvde.exe\n",
      "- wevtutil.exe\n",
      " \n",
      " \n",
      "driverquery.exe\n",
      "- nbtscan.exe\n",
      " \n",
      " \n",
      "ntdsutil.exe\n",
      "- vssadmin.exe\n",
      " \n",
      " \n",
      "dsquery.exe\n",
      "- adfind.exe\n",
      " \n",
      " \n",
      "klist.exe\n",
      "- vssvc.exe\n",
      " \n",
      " | comp count_distinct\n",
      "- node.exe\n",
      "\n",
      " and causality_actor_process_command_line contains\n",
      "- cmd.exe\n",
      "\n",
      "\n",
      "powershell.exe\n",
      "- wget.exe\n",
      "\n",
      " 1 2 3 4 5 6 7 // Description: Identifies a specific causality chain where Node.js spawns a shell\n",
      "- node.exe\n",
      " \n",
      " and causality_actor_process_command_line contains\n",
      "- cmd.exe\n",
      " \n",
      " \n",
      "powershell.exe\n",
      "- wget.exe\n",
      " \n",
      " Conclusion The critical distinction of these vulnerabilities is their nature as a deterministic logic flaw in the Flight protocol\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "def fetch_article(article_id: int) -> str:\n",
    "    cmd = [\n",
    "        'docker','exec','-i','cti_postgres',\n",
    "        'psql','-U','cti_user','-d','cti_scraper',\n",
    "        '-t','-A','-c', f\"SELECT content FROM articles WHERE id={article_id};\"\n",
    "    ]\n",
    "    return subprocess.check_output(cmd).decode().strip()\n",
    "\n",
    "def split_log_blob(text: str) -> str:\n",
    "    # Break log blobs on separators so regex can see individual commands\n",
    "    for sep in [';', '\"', '\\n', ',', '[', ']', '(', ')']:\n",
    "        text = text.replace(sep, '\\n')\n",
    "    return text\n",
    "\n",
    "\n",
    "content = fetch_article(243)\n",
    "pre = split_log_blob(content)\n",
    "candidates = extract_candidate_lines(pre)\n",
    "print(f\"\\nFound {len(candidates)} candidates:\\n\")\n",
    "for c in candidates:\n",
    "    print(\"-\", c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patterns in use:\n",
      " {'exe_with_args': '(?:\"?[A-Za-z]:\\\\\\\\+[^\"\\\\s]+\\\\.\\\\w{3,4}\"?(?:\\\\s+[^\\\\r\\\\n]+))', 'bare_exe_with_args': '(?:[A-Za-z0-9_\\\\-]+\\\\.exe)(?:\\\\s+[^\\\\r\\\\n]+)', 'powershell': '(?:powershell(?:\\\\.exe)?)\\\\s+[^\\\\r\\\\n]+', 'system32_utils': '(?:\"?C:\\\\\\\\+Windows\\\\\\\\+System32\\\\\\\\+(?:net|ipconfig|setspn|quser)\\\\.exe\"?\\\\s+[^\\\\r\\\\n]+)', 'quoted_with_spaces': '\"[A-Za-z]:\\\\\\\\+[^\"\\\\r\\\\n]+?\\\\.\\\\w{3,4}\"(?:\\\\s+[^\\\\r\\\\n]+)'}\n",
      "\n",
      "Found 13 candidates:\n",
      "\n",
      "- C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -ExecutionPolicy Unrestricted -encodedCommand cQB1AHMAZQByAA== Each of the observed PowerShell commands varied only in the encoded commands\n",
      "- C:\\Windows\\system32\\net.exe\n",
      " group\n",
      "- C:\\Windows\\system32\\quser.exe\n",
      " \n",
      "C:\\Windows\\system32\\setspn.exe\n",
      "- C:\\Windows\\system32\\ipconfig.exe\n",
      " /al Figure 2: EDR signals showing the threat actor installing an MSI package\n",
      "- WSUSService.exe before running the Windows installer (as seen via a Service Control Manager/7036 message stating Windows Installer\n",
      "- Velociraptor.exe\n",
      " --config\n",
      "- Velociraptor.exe\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--config\n",
      "- Velociraptor.exe\n",
      " such as the following: C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -ExecutionPolicy Unrestricted -encodedCommand cQB1AHMAZQByAA== Each of the observed PowerShell commands varied only in the encoded commands\n",
      "- net.exe\n",
      " group\n",
      "- quser.exe\n",
      " \n",
      "C:\\Windows\\system32\\setspn.exe\n",
      "- ipconfig.exe\n",
      " /al Figure 2: EDR signals showing the threat actor installing an MSI package\n",
      "- PowerShell commands\n",
      "- powershell.exe -ExecutionPolicy Unrestricted -encodedCommand cQB1AHMAZQByAA== Each of the observed PowerShell commands varied only in the encoded commands\n"
     ]
    }
   ],
   "source": [
    "# Play with regex patterns and see extraction output\n",
    "import re\n",
    "import subprocess\n",
    "from src.extractors import regex_windows\n",
    "\n",
    "def fetch_article(article_id: int) -> str:\n",
    "    cmd = [\n",
    "        'docker', 'exec', '-i', 'cti_postgres',\n",
    "        'psql', '-U', 'cti_user', '-d', 'cti_scraper',\n",
    "        '-t', '-A', '-c', f\"SELECT content FROM articles WHERE id={article_id};\"\n",
    "    ]\n",
    "    return subprocess.check_output(cmd).decode().strip()\n",
    "\n",
    "def split_log_blob(text: str) -> str:\n",
    "    for sep in [';', '\"', '\\n', ',']:\n",
    "        text = text.replace(sep, '\\n')\n",
    "    return text\n",
    "\n",
    "def extract_with_custom_patterns(text: str, overrides: dict[str, str] | None = None):\n",
    "    patterns = regex_windows.DEFAULT_PATTERNS.copy()\n",
    "    patterns.update(overrides or {})  # your edits win\n",
    "    compiled = []\n",
    "    for pat in patterns.values():\n",
    "        try:\n",
    "            compiled.append(re.compile(pat, re.IGNORECASE | re.MULTILINE))\n",
    "        except re.error as exc:\n",
    "            print(f\"Skipping invalid regex: {pat} ({exc})\")\n",
    "    seen, out = set(), []\n",
    "    for pat in compiled:\n",
    "        for m in pat.finditer(text):\n",
    "            val = m.group(0).strip()\n",
    "            if val and val not in seen:\n",
    "                seen.add(val)\n",
    "                out.append(val)\n",
    "    return out, patterns\n",
    "\n",
    "# --- tweak here ---\n",
    "ARTICLE_ID = 68\n",
    "PATTERN_OVERRIDES = {\n",
    "    # Example: loosen embedded exe matching\n",
    "    # \"embedded_exe\": r'(?i)(?:[A-Za-z]:\\\\[^\\s\"]+|[A-Za-z0-9_\\-]+\\.exe)(?:\\s+[^\\r\\n\";,]+)+'\n",
    "\n",
    "}\n",
    "# ------------------\n",
    "\n",
    "content = fetch_article(ARTICLE_ID)\n",
    "pre = split_log_blob(content)\n",
    "candidates, used_patterns = extract_with_custom_patterns(pre, PATTERN_OVERRIDES)\n",
    "\n",
    "print(\"Patterns in use:\\n\", used_patterns)\n",
    "print(f\"\\nFound {len(candidates)} candidates:\\n\")\n",
    "for c in candidates:\n",
    "    print(\"-\", c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML path: /Users/starlord/CTIScraper/resources/regex/windows_cmd_patterns.yaml\n",
      "YAML contents:\n",
      " patterns:\n",
      " exe_with_args: '\"?[A-Za-z]:\\\\\\\\[^\"\\r\\n]+\\.\\w{2,5}\"?\\s+[^\\r\\n]+'\n",
      " bare_exe_with_args: '(?i)(?:^|\\s)([A-Za-z0-9_\\-]+\\.exe)\\s+[^\\r\\n]+'\n",
      " powershell: '(?i)(?:\"?[A-Za-z]:\\\\\\\\[^\"\\r\\n]*\\\\(?:powershell|pwsh)(?:\\.exe)?\"?)\\s+[^\\r\\n]+'\n",
      " system32_utils: '(?i)\"?C:\\\\\\\\Windows\\\\\\\\System32\\\\\\\\(?:net|ipconfig|setspn|quser)\\.exe\"?\\s+[^\\r\\n]+'\n",
      "Defaults: {'exe_with_args': '(?:\"?[A-Za-z]:\\\\\\\\+[^\"\\\\s]+\\\\.\\\\w{3,4}\"?(?:\\\\s+[^\\\\r\\\\n]+))', 'bare_exe_with_args': '(?:[A-Za-z0-9_\\\\-]+\\\\.exe)(?:\\\\s+[^\\\\r\\\\n]+)', 'powershell': '(?:powershell(?:\\\\.exe)?)\\\\s+[^\\\\r\\\\n]+', 'system32_utils': '(?:\"?C:\\\\\\\\+Windows\\\\\\\\+System32\\\\\\\\+(?:net|ipconfig|setspn|quser)\\\\.exe\"?\\\\s+[^\\\\r\\\\n]+)', 'quoted_with_spaces': '\"[A-Za-z]:\\\\\\\\+[^\"\\\\r\\\\n]+?\\\\.\\\\w{3,4}\"(?:\\\\s+[^\\\\r\\\\n]+)'}\n",
      "Overrides: {'exe_with_args': '\"?[A-Za-z]:\\\\\\\\\\\\\\\\[^\"\\\\r\\\\n]+\\\\.\\\\w{2,5}\"?\\\\s+[^\\\\r\\\\n]+', 'bare_exe_with_args': '(?i)(?:^|\\\\s)([A-Za-z0-9_\\\\-]+\\\\.exe)\\\\s+[^\\\\r\\\\n]+', 'powershell': '(?i)(?:\"?[A-Za-z]:\\\\\\\\\\\\\\\\[^\"\\\\r\\\\n]*\\\\\\\\(?:powershell|pwsh)(?:\\\\.exe)?\"?)\\\\s+[^\\\\r\\\\n]+', 'system32_utils': '(?i)\"?C:\\\\\\\\\\\\\\\\Windows\\\\\\\\\\\\\\\\System32\\\\\\\\\\\\\\\\(?:net|ipconfig|setspn|quser)\\\\.exe\"?\\\\s+[^\\\\r\\\\n]+'}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from src.extractors import regex_windows\n",
    "\n",
    "print(\"YAML path:\", Path(regex_windows.__file__).resolve().parents[2] / \"resources/regex/windows_cmd_patterns.yaml\")\n",
    "print(\"YAML contents:\\n\", Path(\"resources/regex/windows_cmd_patterns.yaml\").read_text())\n",
    "\n",
    "print(\"Defaults:\", regex_windows.DEFAULT_PATTERNS)\n",
    "print(\"Overrides:\", regex_windows._load_external_patterns())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
